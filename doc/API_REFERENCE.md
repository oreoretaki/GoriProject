# Stage 1 API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

## ğŸ“š æ¦‚è¦

Stage 1ã®å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ã®è©³ç´°ä»•æ§˜ã‚’è¨˜è¼‰ã€‚é–‹ç™ºè€…ãŒå®Ÿè£…ã‚’ç†è§£ãƒ»æ‹¡å¼µã™ã‚‹éš›ã®å‚è€ƒè³‡æ–™ã€‚

---

## ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### `MultiTFWindowSampler`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/window_sampler.py`

ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰åŒæœŸã•ã‚ŒãŸã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(
    self,
    tf_data: Dict[str, pd.DataFrame],
    seq_len: int,
    split: str = "train",
    val_split: float = 0.2,
    min_coverage: float = 0.8
)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `tf_data`: `{tf_name: DataFrame}` å½¢å¼ã®ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿
- `seq_len`: M1ã§ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
- `split`: `"train"` ã¾ãŸã¯ `"val"`  
- `val_split`: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å‰²åˆ (0.0-1.0)
- `min_coverage`: æœ€å°ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸ (0.0-1.0)

**æˆ»ã‚Šå€¤**: `MultiTFWindowSampler` ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### `__getitem__(idx: int) -> Dict[str, pd.DataFrame]`

æŒ‡å®šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒãƒ«ãƒTFã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å–å¾—ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `idx`: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (0 <= idx < len(sampler))

**æˆ»ã‚Šå€¤**: `{tf_name: DataFrame}` ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒ‡ãƒ¼ã‚¿

**ä¾‹å¤–**:
- `IndexError`: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç¯„å›²å¤–

##### `get_sample_window_info(idx: int = 0) -> Dict`

ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æƒ…å ±å–å¾—ã€‚

**æˆ»ã‚Šå€¤**:
```python
{
    "window_index": int,
    "start_time": pd.Timestamp,
    "end_time": pd.Timestamp, 
    "duration_hours": float,
    "tf_lengths": Dict[str, int]
}
```

---

### `FeatureEngineer`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/feature_engineering.py`

OHLC ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰6ç‰¹å¾´é‡ `[open, high, low, close, Î”close, %body]` ã‚’è¨ˆç®—ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(self, config: dict)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `config`: è¨­å®šè¾æ›¸ (`data.n_features`, `data.timeframes` ã‚’å«ã‚€)

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### `process_window(window_data: Dict[str, pd.DataFrame]) -> Tuple[torch.Tensor, torch.Tensor]`

ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãƒ‡ãƒ¼ã‚¿ã‚’ç‰¹å¾´é‡ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«å¤‰æ›ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `window_data`: `{tf_name: DataFrame}` ãƒãƒ«ãƒTFã‚¦ã‚£ãƒ³ãƒ‰ã‚¦

**æˆ»ã‚Šå€¤**:
- `features`: `[n_tf, seq_len, n_features]` ç‰¹å¾´é‡ãƒ†ãƒ³ã‚½ãƒ«
- `targets`: `[n_tf, seq_len, 4]` ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆOHLCï¼‰ãƒ†ãƒ³ã‚½ãƒ«

##### `get_feature_stats(window_data: Dict[str, pd.DataFrame]) -> Dict`

ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã€‚

**æˆ»ã‚Šå€¤**: TFã”ã¨ã®çµ±è¨ˆæƒ…å ±è¾æ›¸

---

### `MaskingStrategy`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/masking.py`

ãƒ©ãƒ³ãƒ€ãƒ é€£ç¶šãƒ–ãƒ­ãƒƒã‚¯ãƒã‚¹ã‚­ãƒ³ã‚°æˆ¦ç•¥ã®å®Ÿè£…ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(self, config: dict)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `config`: ãƒã‚¹ã‚­ãƒ³ã‚°è¨­å®š (`masking.*` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### `generate_masks(features: torch.Tensor, seed: int = None) -> torch.Tensor`

ãƒãƒ«ãƒTFç‰¹å¾´é‡ç”¨ãƒã‚¹ã‚¯ã‚’ç”Ÿæˆã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `features`: `[batch, n_tf, seq_len, n_features]` ç‰¹å¾´é‡
- `seed`: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆå†ç¾æ€§ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

**æˆ»ã‚Šå€¤**:
- `masks`: `[batch, n_tf, seq_len]` ãƒã‚¹ã‚¯ãƒ†ãƒ³ã‚½ãƒ« (1=ãƒã‚¹ã‚¯, 0=è¦³æ¸¬)

##### `get_mask_statistics(masks: torch.Tensor) -> Dict`

ãƒã‚¹ã‚¯çµ±è¨ˆå–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ã€‚

**æˆ»ã‚Šå€¤**:
```python
{
    tf_name: {
        'mask_ratio': float,
        'masked_tokens': int,
        'total_tokens': int,
        'n_blocks': int,
        'block_lengths': List[int],
        'avg_block_length': float
    }
}
```

---

### `TFNormalizer`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/normalization.py`

ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥z-scoreæ­£è¦åŒ–ã‚¯ãƒ©ã‚¹ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(self, config: dict, cache_stats: bool = True)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `config`: æ­£è¦åŒ–è¨­å®š
- `cache_stats`: çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹/ç„¡åŠ¹

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### `fit(tf_data: Dict[str, pd.DataFrame]) -> None`

è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ­£è¦åŒ–çµ±è¨ˆã‚’è¨ˆç®—ãƒ»ä¿å­˜ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `tf_data`: `{tf_name: DataFrame}` TFãƒ‡ãƒ¼ã‚¿

##### `normalize(features: torch.Tensor) -> torch.Tensor`

ç‰¹å¾´é‡ã‚’æ­£è¦åŒ–ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `features`: `[batch, n_tf, seq_len, n_features]` æ­£è¦åŒ–å‰ç‰¹å¾´é‡

**æˆ»ã‚Šå€¤**:
- `normalized`: æ­£è¦åŒ–å¾Œç‰¹å¾´é‡ (åŒå½¢çŠ¶)

##### `denormalize(normalized: torch.Tensor, tf_indices: Optional[torch.Tensor] = None) -> torch.Tensor`

æ­£è¦åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã‚¹ã‚±ãƒ¼ãƒ«ã«å¾©å…ƒã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `normalized`: æ­£è¦åŒ–æ¸ˆã¿ãƒ†ãƒ³ã‚½ãƒ«
- `tf_indices`: å¯¾è±¡TFã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆNoneã§å…¨TFï¼‰

**æˆ»ã‚Šå€¤**: å…ƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ†ãƒ³ã‚½ãƒ«

---

## ğŸ§  ãƒ¢ãƒ‡ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### `Stage1Model`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/model.py`

ãƒãƒ«ãƒTFè‡ªå·±æ•™å¸«ã‚ã‚Šå†æ§‹ç¯‰ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(self, config: dict)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `config`: ãƒ¢ãƒ‡ãƒ«è¨­å®šè¾æ›¸

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### `forward(features: torch.Tensor, masks: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]`

ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹å®Ÿè¡Œã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `features`: `[batch, n_tf, seq_len, n_features]` å…¥åŠ›ç‰¹å¾´é‡
- `masks`: `[batch, n_tf, seq_len]` ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒã‚¹ã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

**æˆ»ã‚Šå€¤**:
```python
{
    'reconstructed': torch.Tensor,  # [batch, n_tf, seq_len, 4] å†æ§‹ç¯‰OHLC
    'encoded': torch.Tensor         # [batch, n_tf, latent_len, d_model] ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰è¡¨ç¾
}
```

##### `get_model_info() -> Dict`

ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—ã€‚

**æˆ»ã‚Šå€¤**:
```python
{
    'total_parameters': int,
    'trainable_parameters': int,
    'model_size_mb': float,
    'architecture': Dict
}
```

---

### `TFSpecificStem`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/model.py`

TFå›ºæœ‰ã‚¹ãƒ†ãƒ ï¼ˆ1D depth-wise CNNï¼‰ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(self, n_features: int, d_model: int, kernel_size: int = 3)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `n_features`: å…¥åŠ›ç‰¹å¾´é‡æ•°
- `d_model`: å‡ºåŠ›æ¬¡å…ƒæ•°
- `kernel_size`: ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º

#### ãƒ¡ã‚½ãƒƒãƒ‰

##### `forward(x: torch.Tensor) -> torch.Tensor`

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `x`: `[batch, seq_len, n_features]` å…¥åŠ›

**æˆ»ã‚Šå€¤**:
- `out`: `[batch, seq_len, d_model]` æŠ•å½±æ¸ˆã¿ç‰¹å¾´é‡

---

## ğŸ¯ æå¤±é–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### `Stage1CombinedLoss`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/losses.py`

4æˆåˆ†çµ±åˆæå¤±é–¢æ•°ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(self, config: dict)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `config`: æå¤±è¨­å®š (`loss.*` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### `forward(pred: torch.Tensor, target: torch.Tensor, masks: torch.Tensor, m1_data: torch.Tensor = None) -> Dict[str, torch.Tensor]`

çµ±åˆæå¤±è¨ˆç®—ã€‚

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `pred`: `[batch, n_tf, seq_len, 4]` äºˆæ¸¬OHLC
- `target`: `[batch, n_tf, seq_len, 4]` æ­£è§£OHLC
- `masks`: `[batch, n_tf, seq_len]` ãƒã‚¹ã‚¯
- `m1_data`: `[batch, seq_len, 4]` M1ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¯ãƒ­ã‚¹æå¤±ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

**æˆ»ã‚Šå€¤**:
```python
{
    'total': torch.Tensor,      # ç·æå¤±
    'recon_tf': torch.Tensor,   # Huberæå¤±
    'spec_tf': torch.Tensor,    # STFTæå¤±
    'cross': torch.Tensor,      # ã‚¯ãƒ­ã‚¹æ•´åˆæ€§æå¤±  
    'amp_phase': torch.Tensor   # æŒ¯å¹…ä½ç›¸æå¤±
}
```

---

### `HuberLoss`

Huberæå¤±å˜ä½“å®Ÿè£…ã€‚

#### `forward(pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor`

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `pred`, `target`: äºˆæ¸¬ãƒ»æ­£è§£OHLC
- `mask`: ãƒã‚¹ã‚¯ï¼ˆ1=æå¤±è¨ˆç®—å¯¾è±¡ï¼‰

**æˆ»ã‚Šå€¤**: ã‚¹ã‚«ãƒ©ãƒ¼æå¤±

---

### `STFTLoss`

ãƒãƒ«ãƒè§£åƒåº¦STFTæå¤±ã€‚

#### `forward(pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor`

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: `HuberLoss` ã¨åŒæ§˜

**æˆ»ã‚Šå€¤**: STFTæå¤±

---

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### `Stage1Dataset`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/data_loader.py`

PyTorch Datasetå®Ÿè£…ã€‚

#### ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿

```python
def __init__(
    self,
    data_dir: str,
    config: dict,
    split: str = "train",
    cache_stats: bool = True
)
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `data_dir`: Stage 0å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
- `config`: è¨­å®šè¾æ›¸
- `split`: `"train"` ã¾ãŸã¯ `"val"`
- `cache_stats`: æ­£è¦åŒ–çµ±è¨ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹/ç„¡åŠ¹

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### `__getitem__(idx: int) -> Dict[str, torch.Tensor]`

**æˆ»ã‚Šå€¤**:
```python
{
    'features': torch.Tensor,    # [n_tf, seq_len, n_features] ãƒã‚¹ã‚¯æ¸ˆã¿ç‰¹å¾´é‡
    'targets': torch.Tensor,     # [n_tf, seq_len, 4] OHLCæ­£è§£
    'masks': torch.Tensor,       # [n_tf, seq_len] ãƒã‚¹ã‚¯æƒ…å ±
    'tf_ids': torch.Tensor       # [n_tf] TFè­˜åˆ¥å­
}
```

---

### `create_stage1_dataloaders`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/data_loader.py`

DataLoaderãƒšã‚¢ä½œæˆé–¢æ•°ã€‚

```python
def create_stage1_dataloaders(
    data_dir: str,
    config: dict,
    batch_size: Optional[int] = None
) -> Tuple[DataLoader, DataLoader]
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `data_dir`: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- `config`: è¨­å®šè¾æ›¸
- `batch_size`: ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆNoneã§è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å€¤ä½¿ç”¨ï¼‰

**æˆ»ã‚Šå€¤**:
- `train_loader`: è¨“ç·´ç”¨DataLoader
- `val_loader`: æ¤œè¨¼ç”¨DataLoader

---

## ğŸš€ å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### `train_stage1.py`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/train_stage1.py`

#### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°

```bash
python3 scripts/train_stage1.py \
  --config CONFIG_PATH \
  --data_dir DATA_DIR \
  [--gpus GPUS] \
  [--resume_from CHECKPOINT]
```

**å¼•æ•°**:
- `--config`: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆå¿…é ˆï¼‰
- `--data_dir`: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆå¿…é ˆï¼‰
- `--gpus`: GPUæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰
- `--resume_from`: å†é–‹ç”¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

#### å‡ºåŠ›

- ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: `checkpoints/stage1-{epoch}-{val_correlation_mean}.ckpt`
- ãƒ­ã‚°: `logs/stage1/` (TensorBoard)

---

### `evaluate_stage1.py`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `scripts/evaluate_stage1.py`

#### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°

```bash
python3 scripts/evaluate_stage1.py \
  --config CONFIG_PATH \
  --ckpt CHECKPOINT_PATH \
  --data_dir DATA_DIR \
  [--output OUTPUT_FILE]
```

**å¼•æ•°**:
- `--config`: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆå¿…é ˆï¼‰
- `--ckpt`: è©•ä¾¡å¯¾è±¡ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆå¿…é ˆï¼‰
- `--data_dir`: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆå¿…é ˆï¼‰  
- `--output`: çµæœå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: `evaluation_results.json`ï¼‰

#### å‡ºåŠ›JSONå½¢å¼

```json
{
  "correlation_per_tf": {
    "m1": {"mean": 0.85, "ohlc": [0.84, 0.86, 0.84, 0.87]},
    "m5": {"mean": 0.82, "ohlc": [0.81, 0.83, 0.80, 0.85]},
    ...
  },
  "reconstruction_quality": {
    "m1": {"mse": 0.001, "mae": 0.02, "rmse": 0.032},
    ...
  },
  "spectral_delta": {
    "m1": {"per_feature": [0.1, 0.12, 0.11, 0.09], "mean": 0.105},
    ...
  },
  "consistency_ratio": {
    "m5": {"ratio": 0.96, "consistent_samples": 4800, "total_samples": 5000},
    ...
  },
  "summary": {
    "mean_correlation": 0.83,
    "mean_mse": 0.0015,
    "mean_spectral_delta": 0.11,
    "mean_consistency_ratio": 0.95
  }
}
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆAPI

### `test_stage1_data.py`

**ãƒ•ã‚¡ã‚¤ãƒ«**: `tests/test_stage1_data.py`

#### å®Ÿè¡Œ

```bash
cd tests
python3 test_stage1_data.py
```

#### çµ‚äº†ã‚³ãƒ¼ãƒ‰

- `0`: å…¨ãƒ†ã‚¹ãƒˆåˆæ ¼
- `1`: ãƒ†ã‚¹ãƒˆå¤±æ•—

#### ãƒ†ã‚¹ãƒˆé …ç›®

1. **ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µãƒ³ãƒ—ãƒ©ãƒ¼åŸºæœ¬ãƒ†ã‚¹ãƒˆ**
   - æœ‰åŠ¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•° > 0
   - M1ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ä¸€è‡´
   - å…¨TFå«æœ‰ç¢ºèª

2. **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ**
   - å‡ºåŠ›å½¢çŠ¶ç¢ºèª
   - NaN/Infæ¤œå‡º
   - OHLCå¦¥å½“æ€§ç¢ºèª

3. **ãƒã‚¹ã‚­ãƒ³ã‚°æˆ¦ç•¥ãƒ†ã‚¹ãƒˆ** 
   - ãƒã‚¹ã‚¯å½¢çŠ¶ç¢ºèª
   - ãƒã‚¹ã‚¯ç‡ç¯„å›²ç¢ºèª
   - é€£ç¶šãƒ–ãƒ­ãƒƒã‚¯æ¤œè¨¼

4. **æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆ**
   - çµ±è¨ˆè¨ˆç®—ç¢ºèª
   - å½¢çŠ¶ä¿æŒç¢ºèª
   - é€†æ­£è¦åŒ–ç¢ºèª

5. **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±åˆãƒ†ã‚¹ãƒˆ**
   - Stage 0ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
   - ã‚µãƒ³ãƒ—ãƒ«å–å¾—ç¢ºèª
   - å¿…è¦ã‚­ãƒ¼å­˜åœ¨ç¢ºèª

6. **ãƒ‡ãƒ¼ã‚¿æ•´åˆ—ãƒ†ã‚¹ãƒˆ**
   - æ™‚é–“æ•´åˆ—ç¢ºèª
   - OHLCè«–ç†åˆ¶ç´„ç¢ºèª

---

## âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä»•æ§˜

### `configs/base.yaml`

#### ãƒ‡ãƒ¼ã‚¿è¨­å®š
```yaml
data:
  seq_len: 200                    # M1ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
  n_timeframes: 6                 # TFæ•°
  n_features: 6                   # ç‰¹å¾´é‡æ•°  
  timeframes: [m1, m5, m15, m30, h1, h4, d]
  data_dir: "../data/derived"     # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
  stats_file: "stats.json"        # æ­£è¦åŒ–çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«
```

#### ãƒã‚¹ã‚­ãƒ³ã‚°è¨­å®š
```yaml
masking:
  mask_ratio: 0.15                # ãƒã‚¹ã‚¯ç‡
  mask_span_min: 5                # æœ€å°ã‚¹ãƒ‘ãƒ³
  mask_span_max: 60               # æœ€å¤§ã‚¹ãƒ‘ãƒ³  
  sync_across_tf: true            # TFé–“åŒæœŸ
```

#### ãƒ¢ãƒ‡ãƒ«è¨­å®š
```yaml
model:
  tf_stem:
    kernel_size: 3                # CNN ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º
    d_model: 128                  # åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ
  encoder:
    n_layers: 8                   # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å±¤æ•°
    d_model: 128                  # ãƒ¢ãƒ‡ãƒ«æ¬¡å…ƒ
    cross_attn_every: 2           # ã‚¯ãƒ­ã‚¹æ³¨æ„é »åº¦
  bottleneck:
    latent_len: 50                # åœ§ç¸®é•·  
    stride: 4                     # ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰
```

#### è¨“ç·´è¨­å®š
```yaml
training:
  batch_size: 24                  # ãƒãƒƒãƒã‚µã‚¤ã‚º
  epochs: 40                      # ã‚¨ãƒãƒƒã‚¯æ•°
  optimizer:
    name: "AdamW"
    betas: [0.9, 0.98]
    weight_decay: 0.01
  scheduler:
    name: "OneCycleLR"
    max_lr: 5.0e-4
    div_factor: 3.33
    final_div_factor: 50
```

---

## ğŸ”— å‹ãƒ’ãƒ³ãƒˆ

### ä¸»è¦å‹å®šç¾©

```python
from typing import Dict, List, Tuple, Optional, Union
import torch
import pandas as pd

# ãƒ‡ãƒ¼ã‚¿å‹
TFData = Dict[str, pd.DataFrame]
WindowData = Dict[str, pd.DataFrame]
ConfigDict = Dict[str, any]

# ãƒ†ãƒ³ã‚½ãƒ«å‹
FeatureTensor = torch.Tensor  # [batch, n_tf, seq_len, n_features]
TargetTensor = torch.Tensor   # [batch, n_tf, seq_len, 4]
MaskTensor = torch.Tensor     # [batch, n_tf, seq_len]

# å‡ºåŠ›å‹
ModelOutput = Dict[str, torch.Tensor]
LossOutput = Dict[str, torch.Tensor]
MetricsOutput = Dict[str, Union[float, Dict]]
```

---

ã“ã® API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã«ã‚ˆã‚Šã€Stage 1 ã®å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è©³ç´°ä»•æ§˜ãŒç¶²ç¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚é–‹ç™ºè€…ã¯å„ã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°ã®æ­£ç¢ºãªä½¿ç”¨æ–¹æ³•ã‚’ç†è§£ã—ã€åŠ¹ç‡çš„ã«é–‹ç™ºãƒ»ãƒ‡ãƒãƒƒã‚°ãƒ»æ‹¡å¼µãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚