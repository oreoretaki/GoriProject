#!/usr/bin/env python3
"""
æå¤±é–¢æ•°ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆï¼ˆå‹¾é…ãƒã‚§ãƒƒã‚¯å«ã‚€ï¼‰
"""

import pytest
import torch
import numpy as np
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’PATHã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from stage1.src.losses import (
    Stage1CombinedLoss,
    HuberLoss,
    MultiResolutionSTFTLoss,
    CrossTFConsistencyLoss,
    AmplitudePhaseCorrelationLoss
)

class TestLossFunctions:
    """æå¤±é–¢æ•°ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    @pytest.fixture
    def config(self):
        """ãƒ†ã‚¹ãƒˆç”¨è¨­å®š"""
        return {
            'data': {
                'n_timeframes': 6,
                'seq_len': 200,
                'timeframes': ['m1', 'm5', 'm15', 'm30', 'h1', 'h4']
            },
            'loss': {
                'weights': {
                    'recon_tf': 0.6,
                    'spec_tf': 0.2,
                    'cross': 0.15,
                    'amp_phase': 0.05
                },
                'huber_delta': 1.0,
                'stft_scales': [256, 512, 1024]
            }
        }
    
    @pytest.fixture
    def sample_data(self, config):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        batch_size = 4
        n_tf = config['data']['n_timeframes']
        seq_len = config['data']['seq_len']
        
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå‹¾é…ãƒã‚§ãƒƒã‚¯ç”¨ã« requires_grad=Trueï¼‰
        reconstructed = torch.randn(batch_size, n_tf, seq_len, 4, requires_grad=True)
        targets = torch.randn(batch_size, n_tf, seq_len, 4)
        masks = torch.randint(0, 2, (batch_size, n_tf, seq_len)).float()
        m1_data = torch.randn(batch_size, seq_len, 4)
        
        # ãƒã‚¹ã‚¯ãŒç©ºã«ãªã‚‰ãªã„ã‚ˆã†èª¿æ•´
        if masks.sum() == 0:
            masks[:, :, :10] = 1.0  # æœ€åˆã®10è¦ç´ ã‚’ãƒã‚¹ã‚¯
        
        return {
            'reconstructed': reconstructed,
            'targets': targets,
            'masks': masks,
            'm1_data': m1_data
        }

class TestHuberLoss(TestLossFunctions):
    """Huberæå¤±ãƒ†ã‚¹ãƒˆ"""
    
    def test_huber_loss_basic(self, config, sample_data):
        """åŸºæœ¬çš„ãªHuberæå¤±ãƒ†ã‚¹ãƒˆ"""
        loss_fn = HuberLoss(delta=config['loss']['huber_delta'])
        
        pred = sample_data['reconstructed'][:, 0]  # æœ€åˆã®TFã®ã¿
        target = sample_data['targets'][:, 0]
        mask = sample_data['masks'][:, 0]
        
        loss = loss_fn(pred, target, mask)
        
        assert loss.item() >= 0, "æå¤±ã¯éè² ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        assert not torch.isnan(loss), "æå¤±ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
        assert not torch.isinf(loss), "æå¤±ã«infãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
    
    def test_huber_loss_gradcheck(self, config):
        """Huberæå¤±å‹¾é…ãƒã‚§ãƒƒã‚¯"""
        loss_fn = HuberLoss(delta=config['loss']['huber_delta'])
        
        # å°ã•ãªãƒ‡ãƒ¼ã‚¿ã§å‹¾é…ãƒã‚§ãƒƒã‚¯
        pred = torch.randn(2, 10, 4, requires_grad=True, dtype=torch.double)
        target = torch.randn(2, 10, 4, dtype=torch.double)
        mask = torch.ones(2, 10, dtype=torch.double)
        
        def loss_func(pred_input):
            return loss_fn(pred_input, target, mask)
        
        # å‹¾é…ãƒã‚§ãƒƒã‚¯
        gradcheck_result = torch.autograd.gradcheck(
            loss_func, pred, eps=1e-6, atol=1e-4, rtol=1e-3
        )
        assert gradcheck_result, "Huberæå¤±ã®å‹¾é…ãƒã‚§ãƒƒã‚¯ãŒå¤±æ•—ã—ã¾ã—ãŸ"

class TestMultiResolutionSTFTLoss(TestLossFunctions):
    """ãƒãƒ«ãƒè§£åƒåº¦STFTæå¤±ãƒ†ã‚¹ãƒˆ"""
    
    def test_stft_loss_basic(self, config, sample_data):
        """åŸºæœ¬çš„ãªSTFTæå¤±ãƒ†ã‚¹ãƒˆ"""
        loss_fn = MultiResolutionSTFTLoss(
            stft_scales=config['loss']['stft_scales']
        )
        
        pred = sample_data['reconstructed'][:, 0, :, 3]  # Closeä¾¡æ ¼ã®ã¿
        target = sample_data['targets'][:, 0, :, 3]
        mask = sample_data['masks'][:, 0]
        
        loss = loss_fn(pred, target, mask)
        
        assert loss.item() >= 0, "STFTæå¤±ã¯éè² ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        assert not torch.isnan(loss), "STFTæå¤±ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™"

class TestCrossTFConsistencyLoss(TestLossFunctions):
    """ã‚¯ãƒ­ã‚¹TFæ•´åˆæ€§æå¤±ãƒ†ã‚¹ãƒˆ"""
    
    def test_cross_tf_loss_basic(self, config, sample_data):
        """åŸºæœ¬çš„ãªã‚¯ãƒ­ã‚¹TFæå¤±ãƒ†ã‚¹ãƒˆ"""
        loss_fn = CrossTFConsistencyLoss()
        
        reconstructed = sample_data['reconstructed']
        m1_data = sample_data['m1_data']
        
        loss = loss_fn(reconstructed, m1_data)
        
        assert loss.item() >= 0, "ã‚¯ãƒ­ã‚¹TFæå¤±ã¯éè² ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        assert not torch.isnan(loss), "ã‚¯ãƒ­ã‚¹TFæå¤±ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™"

class TestAmplitudePhaseCorrelationLoss(TestLossFunctions):
    """æŒ¯å¹…ãƒ»ä½ç›¸ç›¸é–¢æå¤±ãƒ†ã‚¹ãƒˆ"""
    
    def test_amp_phase_loss_basic(self, config, sample_data):
        """åŸºæœ¬çš„ãªæŒ¯å¹…ãƒ»ä½ç›¸æå¤±ãƒ†ã‚¹ãƒˆ"""
        loss_fn = AmplitudePhaseCorrelationLoss()
        
        pred = sample_data['reconstructed'][:, 0, :, 3]  # Closeä¾¡æ ¼
        target = sample_data['targets'][:, 0, :, 3]
        mask = sample_data['masks'][:, 0]
        
        loss = loss_fn(pred, target, mask)
        
        assert loss.item() >= 0, "æŒ¯å¹…ãƒ»ä½ç›¸æå¤±ã¯éè² ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™"
        assert not torch.isnan(loss), "æŒ¯å¹…ãƒ»ä½ç›¸æå¤±ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™"

class TestCombinedLoss(TestLossFunctions):
    """çµ±åˆæå¤±ãƒ†ã‚¹ãƒˆ"""
    
    def test_combined_loss_basic(self, config, sample_data):
        """åŸºæœ¬çš„ãªçµ±åˆæå¤±ãƒ†ã‚¹ãƒˆ"""
        loss_fn = Stage1CombinedLoss(config)
        
        losses = loss_fn(
            sample_data['reconstructed'],
            sample_data['targets'],
            sample_data['masks'],
            sample_data['m1_data']
        )
        
        # æœŸå¾…ã•ã‚Œã‚‹ã‚­ãƒ¼ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        expected_keys = ['recon_tf', 'spec_tf', 'cross', 'amp_phase', 'total']
        for key in expected_keys:
            assert key in losses, f"æå¤±è¾æ›¸ã«'{key}'ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
            assert not torch.isnan(losses[key]), f"æå¤±'{key}'ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
            assert losses[key].item() >= 0, f"æå¤±'{key}'ãŒè² ã®å€¤ã§ã™"
    
    def test_combined_loss_weights(self, config, sample_data):
        """çµ±åˆæå¤±ã®é‡ã¿ä»˜ã‘ãƒ†ã‚¹ãƒˆ"""
        loss_fn = Stage1CombinedLoss(config)
        
        losses = loss_fn(
            sample_data['reconstructed'],
            sample_data['targets'],
            sample_data['masks'],
            sample_data['m1_data']
        )
        
        # é‡ã¿ä»˜ã‘ç¢ºèªï¼ˆè¿‘ä¼¼çš„ã«ï¼‰
        weights = config['loss']['weights']
        expected_total = (
            losses['recon_tf'] * weights['recon_tf'] +
            losses['spec_tf'] * weights['spec_tf'] +
            losses['cross'] * weights['cross'] +
            losses['amp_phase'] * weights['amp_phase']
        )
        
        # æµ®å‹•å°æ•°ç‚¹èª¤å·®ã‚’è€ƒæ…®ã—ãŸæ¯”è¼ƒ
        diff = torch.abs(losses['total'] - expected_total)
        assert diff < 1e-5, f"ç·æå¤±ã®é‡ã¿ä»˜ã‘ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“: diff={diff}"
    
    def test_combined_loss_gradcheck(self, config):
        """çµ±åˆæå¤±å‹¾é…ãƒã‚§ãƒƒã‚¯"""
        # ã‚ˆã‚Šå°ã•ãªãƒ‡ãƒ¼ã‚¿ã§é«˜é€Ÿãƒ†ã‚¹ãƒˆ
        small_config = config.copy()
        small_config['data']['seq_len'] = 20
        small_config['data']['n_timeframes'] = 2
        
        loss_fn = Stage1CombinedLoss(small_config)
        
        batch_size = 2
        n_tf = 2
        seq_len = 20
        
        reconstructed = torch.randn(batch_size, n_tf, seq_len, 4, 
                                  requires_grad=True, dtype=torch.double)
        targets = torch.randn(batch_size, n_tf, seq_len, 4, dtype=torch.double)
        masks = torch.ones(batch_size, n_tf, seq_len, dtype=torch.double)
        m1_data = torch.randn(batch_size, seq_len, 4, dtype=torch.double)
        
        def loss_func(recon_input):
            losses = loss_fn(recon_input, targets, masks, m1_data)
            return losses['total']
        
        # å‹¾é…ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        try:
            gradcheck_result = torch.autograd.gradcheck(
                loss_func, reconstructed, eps=1e-4, atol=1e-3, rtol=1e-2
            )
            assert gradcheck_result, "çµ±åˆæå¤±ã®å‹¾é…ãƒã‚§ãƒƒã‚¯ãŒå¤±æ•—ã—ã¾ã—ãŸ"
        except Exception as e:
            # æ•°å€¤çš„ãªå•é¡Œã§å¤±æ•—ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ã€è­¦å‘Šã¨ã—ã¦æ‰±ã†
            print(f"âš ï¸ å‹¾é…ãƒã‚§ãƒƒã‚¯è­¦å‘Š: {str(e)}")

class TestLossEdgeCases:
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_empty_mask(self, config):
        """ç©ºã®ãƒã‚¹ã‚¯ã«å¯¾ã™ã‚‹ãƒ†ã‚¹ãƒˆ"""
        loss_fn = Stage1CombinedLoss(config)
        
        batch_size = 2
        n_tf = config['data']['n_timeframes']
        seq_len = config['data']['seq_len']
        
        reconstructed = torch.randn(batch_size, n_tf, seq_len, 4)
        targets = torch.randn(batch_size, n_tf, seq_len, 4)
        masks = torch.zeros(batch_size, n_tf, seq_len)  # å…¨ã¦ã‚¼ãƒ­ãƒã‚¹ã‚¯
        m1_data = torch.randn(batch_size, seq_len, 4)
        
        losses = loss_fn(reconstructed, targets, masks, m1_data)
        
        # ç©ºã®ãƒã‚¹ã‚¯ã§ã‚‚é©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨
        assert not torch.isnan(losses['total'])
    
    def test_all_mask(self, config):
        """å…¨ã¦ãƒã‚¹ã‚¯ã•ã‚ŒãŸå ´åˆã®ãƒ†ã‚¹ãƒˆ"""
        loss_fn = Stage1CombinedLoss(config)
        
        batch_size = 2
        n_tf = config['data']['n_timeframes']
        seq_len = config['data']['seq_len']
        
        reconstructed = torch.randn(batch_size, n_tf, seq_len, 4)
        targets = torch.randn(batch_size, n_tf, seq_len, 4)
        masks = torch.ones(batch_size, n_tf, seq_len)  # å…¨ã¦ãƒã‚¹ã‚¯
        m1_data = torch.randn(batch_size, seq_len, 4)
        
        losses = loss_fn(reconstructed, targets, masks, m1_data)
        
        # å…¨ã¦ãƒã‚¹ã‚¯ã§ã‚‚é©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨
        assert not torch.isnan(losses['total'])
        assert losses['total'].item() >= 0

# pytestå®Ÿè¡Œç”¨
if __name__ == "__main__":
    # ç°¡å˜ãªå®Ÿè¡Œç¢ºèª
    print("ğŸ§ª æå¤±é–¢æ•°ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    
    # è¨­å®šã¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
    config = {
        'data': {
            'n_timeframes': 6,
            'seq_len': 200,
            'timeframes': ['m1', 'm5', 'm15', 'm30', 'h1', 'h4']
        },
        'loss': {
            'weights': {
                'recon_tf': 0.6,
                'spec_tf': 0.2,
                'cross': 0.15,
                'amp_phase': 0.05
            },
            'huber_delta': 1.0,
            'stft_scales': [256, 512]  # é«˜é€ŸåŒ–ã®ãŸã‚çŸ­ç¸®
        }
    }
    
    # åŸºæœ¬ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_class = TestCombinedLoss()
    sample_data = {
        'reconstructed': torch.randn(2, 6, 50, 4, requires_grad=True),
        'targets': torch.randn(2, 6, 50, 4),
        'masks': torch.randint(0, 2, (2, 6, 50)).float(),
        'm1_data': torch.randn(2, 50, 4)
    }
    
    try:
        test_class.test_combined_loss_basic(config, sample_data)
        test_class.test_combined_loss_weights(config, sample_data)
        print("âœ… åŸºæœ¬ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
    
    print("ğŸ¯ ãƒ†ã‚¹ãƒˆå®Œäº†")