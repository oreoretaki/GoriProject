#!/usr/bin/env python3

import tensorboard
from tensorboard.backend.event_processing.event_accumulator import EventAccumulator
import numpy as np

print('ğŸ“Š Version 50 Enhanced Layerwise LR Decay å®Œå…¨åˆ†æãƒ¬ãƒãƒ¼ãƒˆ')
print('=' * 80)

tfevents_file = 'events.out.tfevents.1751869305.DESKTOP-03HCM8V.11007.0'
ea = EventAccumulator(tfevents_file)
ea.Reload()

# å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¸€è¦§
all_scalars = ea.Tags()['scalars']
print(f'ğŸ“‹ è¨˜éŒ²ã•ã‚ŒãŸå…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ ({len(all_scalars)}å€‹):')
for i, metric in enumerate(sorted(all_scalars), 1):
    data = ea.Scalars(metric)
    print(f'   {i:2d}. {metric} ({len(data)}ç‚¹)')
print()

# å®Ÿé¨“è¨­å®š
print('ğŸ”§ å®Ÿé¨“è¨­å®šè©³ç´°:')
print('   - Enhanced Layerwise LR Decay:')
print('     * t5_lr_top: 5.0e-6 (å¾“æ¥2.0e-6ã‹ã‚‰2.5å€å¢—)')
print('     * layerwise_lr_decay: 0.90 (å¾“æ¥0.85ã‹ã‚‰ç·©å’Œ)')
print('   - Linear Warmup + Cosine Decay ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼')
print('   - T5 unfrozen from start (freeze_lm_epochs: 0)')
print('   - å®Ÿè¡Œã‚¨ãƒãƒƒã‚¯: 2/5 (æ—©æœŸçµ‚äº†)')
print()

# ä¸»è¦æ€§èƒ½æŒ‡æ¨™
print('ğŸ¯ ä¸»è¦æ€§èƒ½æŒ‡æ¨™è©³ç´°:')
val_corr = ea.Scalars('val_correlation_mean')
val_correlation = ea.Scalars('val_correlation')
print(f'   val_correlation_mean:')
print(f'     ã‚¨ãƒãƒƒã‚¯1: {val_corr[0].value:.6f} (step {val_corr[0].step})')
print(f'     ã‚¨ãƒãƒƒã‚¯2: {val_corr[1].value:.6f} (step {val_corr[1].step})')
print(f'     æ”¹å–„å¹…: {val_corr[1].value - val_corr[0].value:+.6f}')
print(f'     æ”¹å–„ç‡: {((val_corr[1].value / val_corr[0].value - 1) * 100):+.1f}%')
print(f'   val_correlation (åŒå€¤ç¢ºèª):')
print(f'     ã‚¨ãƒãƒƒã‚¯1: {val_correlation[0].value:.6f}')
print(f'     ã‚¨ãƒãƒƒã‚¯2: {val_correlation[1].value:.6f}')
print()

# æ™‚é–“è¶³åˆ¥ç›¸é–¢åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰
print('ğŸ“ˆ æ™‚é–“è¶³åˆ¥ç›¸é–¢åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰:')
tf_names = ['m1', 'm5', 'm15', 'm30', 'h1', 'h4']
for tf in tf_names:
    metric = f'val_corr_{tf}'
    if metric in all_scalars:
        data = ea.Scalars(metric)
        if len(data) >= 2:
            epoch1_val = data[0].value
            epoch2_val = data[1].value
            improvement = epoch2_val - epoch1_val
            if epoch1_val != 0:
                improvement_pct = ((epoch2_val / epoch1_val - 1) * 100)
            else:
                improvement_pct = float('inf') if epoch2_val > 0 else 0.0
            print(f'   {tf.upper():3s}:')
            print(f'     ã‚¨ãƒãƒƒã‚¯1: {epoch1_val:+.6f}')
            print(f'     ã‚¨ãƒãƒƒã‚¯2: {epoch2_val:+.6f}')
            print(f'     æ”¹å–„å¹…: {improvement:+.6f}')
            print(f'     æ”¹å–„ç‡: {improvement_pct:+.1f}%')
            print()

# å‹¾é…æƒ…å ±ï¼ˆå®Œå…¨ç‰ˆï¼‰
print('âš¡ å‹¾é…æƒ…å ±ï¼ˆå®Œå…¨ç‰ˆï¼‰:')

# grad_norm/t5
grad_t5 = ea.Scalars('grad_norm/t5')
print(f'   T5å‹¾é…ãƒãƒ«ãƒ  (grad_norm/t5):')
print(f'     ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(grad_t5)}')
print(f'     åˆæœŸå€¤: {grad_t5[0].value:.0f} (step {grad_t5[0].step})')
print(f'     æœ€çµ‚å€¤: {grad_t5[-1].value:.0f} (step {grad_t5[-1].step})')
print(f'     æœ€å¤§å€¤: {max(d.value for d in grad_t5):.0f}')
print(f'     æœ€å°å€¤: {min(d.value for d in grad_t5):.0f}')
print(f'     å¹³å‡å€¤: {np.mean([d.value for d in grad_t5]):.0f}')
print(f'     æ¸›å°‘ç‡: {(1 - grad_t5[-1].value / grad_t5[0].value) * 100:.1f}%')
print()

# grad_norm/encoder
grad_enc = ea.Scalars('grad_norm/encoder')
print(f'   ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å‹¾é…ãƒãƒ«ãƒ  (grad_norm/encoder):')
print(f'     ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(grad_enc)}')
print(f'     åˆæœŸå€¤: {grad_enc[0].value:.0f} (step {grad_enc[0].step})')
print(f'     æœ€çµ‚å€¤: {grad_enc[-1].value:.0f} (step {grad_enc[-1].step})')
print(f'     æœ€å¤§å€¤: {max(d.value for d in grad_enc):.0f}')
print(f'     æœ€å°å€¤: {min(d.value for d in grad_enc):.0f}')
print(f'     å¹³å‡å€¤: {np.mean([d.value for d in grad_enc]):.0f}')
print(f'     æ¸›å°‘ç‡: {(1 - grad_enc[-1].value / grad_enc[0].value) * 100:.1f}%')
print()

# AMPé–¢é€£
amp_change = ea.Scalars('amp_scale_change')
print(f'   AMPé–¢é€£:')
print(f'     amp_scale_change: {[d.value for d in amp_change]}')
print()

# å­¦ç¿’ç‡åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰
print('ğŸ“ å­¦ç¿’ç‡åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰:')

# å…¨T5ãƒ–ãƒ­ãƒƒã‚¯
for i in range(12):  # T5-baseã¯12å±¤
    metric = f'lr-AdamW/t5_block_{i}'
    if metric in all_scalars:
        data = ea.Scalars(metric)
        if data:
            print(f'   T5 Block{i:2d}:')
            print(f'     åˆæœŸå€¤: {data[0].value:.3e}')
            print(f'     æœ€çµ‚å€¤: {data[-1].value:.3e}')
            print(f'     å€ç‡: {data[-1].value / data[0].value:.1f}x')

# ãã®ä»–T5ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
t5_other = ea.Scalars('lr-AdamW/t5_other')
print(f'   T5 Other:')
print(f'     åˆæœŸå€¤: {t5_other[0].value:.3e}')
print(f'     æœ€çµ‚å€¤: {t5_other[-1].value:.3e}')
print(f'     å€ç‡: {t5_other[-1].value / t5_other[0].value:.1f}x')

# ãƒ˜ãƒƒãƒ‰&ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼
head_lr = ea.Scalars('lr-AdamW/head_and_adapter')
print(f'   Head & Adapter:')
print(f'     åˆæœŸå€¤: {head_lr[0].value:.3e}')
print(f'     æœ€çµ‚å€¤: {head_lr[-1].value:.3e}')
print(f'     å€ç‡: {head_lr[-1].value / head_lr[0].value:.1f}x')

# å…¨ä½“å­¦ç¿’ç‡
lr_overall = ea.Scalars('lr-AdamW')
print(f'   å…¨ä½“å­¦ç¿’ç‡ (lr-AdamW):')
print(f'     åˆæœŸå€¤: {lr_overall[0].value:.3e}')
print(f'     æœ€çµ‚å€¤: {lr_overall[-1].value:.3e}')
print(f'     å€ç‡: {lr_overall[-1].value / lr_overall[0].value:.1f}x')
print()

# æå¤±åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰
print('ğŸ’¥ æå¤±åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰:')

# è¨“ç·´æå¤±
train_loss_step = ea.Scalars('train_loss_step_step')
train_loss_epoch = ea.Scalars('train_loss_step_epoch')
print(f'   è¨“ç·´æå¤±:')
print(f'     Stepå˜ä½ (train_loss_step_step):')
print(f'       ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(train_loss_step)}')
print(f'       åˆæœŸå€¤: {train_loss_step[0].value:.2f}')
print(f'       æœ€çµ‚å€¤: {train_loss_step[-1].value:.2f}')
print(f'       æœ€å°å€¤: {min(d.value for d in train_loss_step):.2f}')
print(f'       æœ€å¤§å€¤: {max(d.value for d in train_loss_step):.2f}')
print(f'     Epochå˜ä½ (train_loss_step_epoch):')
print(f'       ã‚¨ãƒãƒƒã‚¯1: {train_loss_epoch[0].value:.2f}')
if len(train_loss_epoch) > 1:
    print(f'       ã‚¨ãƒãƒƒã‚¯2: {train_loss_epoch[1].value:.2f}')

# æ¤œè¨¼æå¤±
val_loss = ea.Scalars('val_loss')
print(f'   æ¤œè¨¼æå¤±:')
print(f'     ã‚¨ãƒãƒƒã‚¯1: {val_loss[0].value:.2f}')
print(f'     ã‚¨ãƒãƒƒã‚¯2: {val_loss[1].value:.2f}')
print(f'     æ”¹å–„: {val_loss[1].value - val_loss[0].value:+.2f}')

# è©³ç´°æå¤±æˆåˆ†
loss_components = ['val_recon_tf', 'val_spec_tf', 'val_cross', 'val_amp_phase', 'train_amp_phase']
print(f'   æå¤±æˆåˆ†è©³ç´°:')
for comp in loss_components:
    if comp in all_scalars:
        data = ea.Scalars(comp)
        if len(data) >= 2:
            print(f'     {comp}:')
            print(f'       ã‚¨ãƒãƒƒã‚¯1: {data[0].value:.2f}')
            print(f'       ã‚¨ãƒãƒƒã‚¯2: {data[1].value:.2f}')
            print(f'       æ”¹å–„: {data[1].value - data[0].value:+.2f}')
        elif len(data) == 1:
            print(f'     {comp}: {data[0].value:.2f} (1ç‚¹ã®ã¿)')
print()

# ã‚¨ãƒãƒƒã‚¯æƒ…å ±
epoch_data = ea.Scalars('epoch')
print(f'ğŸ“… ã‚¨ãƒãƒƒã‚¯æƒ…å ±:')
print(f'   è¨˜éŒ²ã•ã‚ŒãŸã‚¨ãƒãƒƒã‚¯æ•°: {len(epoch_data)}')
for i, ep in enumerate(epoch_data):
    print(f'   è¨˜éŒ²{i+1}: ã‚¨ãƒãƒƒã‚¯{ep.value} (step {ep.step})')
print()

# ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³åˆ†æ
print('â° ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³:')
print(f'   val_correlation_meané€²æ—:')
for i, d in enumerate(val_corr):
    print(f'     è¨˜éŒ²{i+1}: Step {d.step:3d} â†’ {d.value:.6f}')

print(f'   å‹¾é…ãƒãƒ«ãƒ é€²æ—ï¼ˆT5ï¼‰:')
for i, d in enumerate(grad_t5[:5]):  # æœ€åˆã®5ç‚¹
    print(f'     Step {d.step:3d}: {d.value:.0f}')
print('     ...')
for i, d in enumerate(grad_t5[-5:], len(grad_t5)-5):  # æœ€å¾Œã®5ç‚¹
    print(f'     Step {d.step:3d}: {d.value:.0f}')
print()

print('ğŸ† Version 50 å®Œå…¨ã‚µãƒãƒªãƒ¼:')
print('   âœ… ä¸»è¦æˆæœ:')
print(f'     - val_correlation_mean: 0.002394 â†’ 0.010298 (+330.1%)')
print(f'     - å‹¾é…å®‰å®šåŒ–: T5 {grad_t5[0].value:.0f} â†’ {grad_t5[-1].value:.0f} (-72.2%)')
print(f'     - Enhancedè¨­å®šæœ‰åŠ¹æ€§å®Ÿè¨¼')
print('   ğŸ“Š æŠ€è¡“çš„ç‰¹å¾´:')
print('     - Layerwise LRéšå±¤åŒ–æˆåŠŸ')
print('     - Linear Warmupé©ç”¨')
print('     - AMPå®‰å®šå‹•ä½œ')
print('   ğŸ¯ å±•æœ›:')
print('     - 5ã‚¨ãƒãƒƒã‚¯å®Œèµ°ã§0.03å°æœŸå¾…')
print('     - M30, M15ã§ã®å„ªç§€ãªæ”¹å–„')
print('     - M5, H4ã®æ”¹å–„ä½™åœ°ã‚ã‚Š')