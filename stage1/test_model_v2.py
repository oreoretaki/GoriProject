#!/usr/bin/env python3
"""
Model v2 ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Œå…¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ä¿®æ­£ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã‹ã‚’ç¢ºèª
"""

import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’PATHã«è¿½åŠ 
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(current_dir))

import torch
import numpy as np
from src.data_loader import create_stage1_dataloaders, collate_multiscale
from src.model import Stage1Model
from src.losses import Stage1CombinedLoss
from src.masking import MaskingStrategy

# ç°¡å˜ãªãƒ†ã‚¹ãƒˆè¨­å®š
test_config = {
    'data': {
        'timeframes': ['m1', 'm5', 'm15', 'h1'],
        'n_timeframes': 4,
        'seq_len': 64,  # å°ã•ãã—ã¦ãƒ†ã‚¹ãƒˆé«˜é€ŸåŒ–
        'n_features': 6,
        'data_dir': '../data/derived',
        'stats_file': 'normalization_stats.json'
    },
    'model': {
        'async_sampler': True,  # Model v2ãƒ†ã‚¹ãƒˆ
        'cross_pairs': [["h1", "m1"], ["m15", "m1"]],
        'tf_stem': {
            'kernel_size': 3,
            'd_model': 128  # å°ã•ãã—ã¦ãƒ†ã‚¹ãƒˆé«˜é€ŸåŒ–
        },
        'encoder': {
            'n_layers': 2,
            'd_model': 128,
            'cross_attn_every': 1
        },
        'bottleneck': {
            'latent_len': 8,
            'stride': 4
        },
        'decoder': {
            'n_layers': 2
        }
    },
    'masking': {
        'mask_ratio': 0.15,
        'mask_span_min': 2,
        'mask_span_max': 8,
        'sync_across_tf': True
    },
    'loss': {
        'weights': {
            'recon_tf': 1.0,
            'spec_tf': 0.1,
            'cross': 0.1,
            'amp_phase': 0.05
        },
        'huber_delta': 1.0,
        'stft_scales': [64, 128]
    },
    'training': {
        'batch_size': 4  # å°ã•ãã—ã¦ãƒ†ã‚¹ãƒˆé«˜é€ŸåŒ–
    },
    'validation': {
        'val_split': 0.2,
        'val_gap_days': 1.0
    },
    'evaluation': {
        'eval_mask_ratio': 0.15
    },
    'dataloader': {
        'num_workers': 0,  # ãƒ†ã‚¹ãƒˆç”¨ã«0
        'pin_memory': False
    }
}

def test_dict_collate():
    """collate_multiscaleé–¢æ•°ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Testing collate_multiscale...")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ï¼ˆDictå½¢å¼ï¼‰
    batch = [
        {
            'features': {
                'm1': torch.randn(64, 6),
                'm5': torch.randn(13, 6),  # ç•°ãªã‚‹é•·ã•
                'h1': torch.randn(2, 6)
            },
            'targets': {
                'm1': torch.randn(64, 4),
                'm5': torch.randn(13, 4),
                'h1': torch.randn(2, 4)
            }
        },
        {
            'features': {
                'm1': torch.randn(64, 6),
                'm5': torch.randn(10, 6),  # ç•°ãªã‚‹é•·ã•
                'h1': torch.randn(1, 6)
            },
            'targets': {
                'm1': torch.randn(64, 4),
                'm5': torch.randn(10, 4),
                'h1': torch.randn(1, 4)
            }
        }
    ]
    
    result = collate_multiscale(batch)
    
    print(f"   âœ… Collateçµæœ:")
    for key, tf_dict in result.items():
        print(f"      {key}:")
        for tf, tensor in tf_dict.items():
            print(f"        {tf}: {tensor.shape}")
    
    return result

def test_masking_strategy_dict():
    """MaskingStrategy Dictå¯¾å¿œãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Testing MaskingStrategy Dict support...")
    
    masking = MaskingStrategy(test_config, n_features=6)
    
    # Dictå½¢å¼ã®features
    features = {
        'm1': torch.randn(2, 64, 6),
        'm5': torch.randn(2, 13, 6),
        'h1': torch.randn(2, 2, 6)
    }
    
    # NaNãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    features['m5'][:, 10:, :] = float('nan')
    features['h1'][:, 1:, :] = float('nan')
    
    masks = masking.generate_masks(features, seed=42)
    
    print(f"   âœ… Maskingçµæœ:")
    for tf, mask in masks.items():
        print(f"      {tf}: {mask.shape}, mask_ratio={mask.float().mean():.3f}")
    
    # ãƒã‚¹ã‚¯é©ç”¨ãƒ†ã‚¹ãƒˆ
    masked_features = masking.apply_mask_to_features(features, masks)
    
    print(f"   âœ… Maské©ç”¨å®Œäº†")
    
    return masks, masked_features

def test_model_v2_forward():
    """Stage1Model Dictå¯¾å¿œãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Testing Stage1Model Dict forward...")
    
    model = Stage1Model(test_config)
    model.eval()
    
    # Dictå½¢å¼ã®å…¥åŠ›
    batch = {
        'm1': torch.randn(2, 64, 6),
        'm5': torch.randn(2, 13, 6),
        'h1': torch.randn(2, 2, 6)
    }
    
    # NaNãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    batch['m5'][:, 10:, :] = float('nan')
    batch['h1'][:, 1:, :] = float('nan')
    
    with torch.no_grad():
        outputs = model(batch, eval_mask_ratio=0.15)
    
    print(f"   âœ… Model forwardçµæœ:")
    for tf, output in outputs.items():
        print(f"      {tf}: {output.shape}")
    
    return outputs

def test_loss_dict():
    """Stage1CombinedLoss Dictå¯¾å¿œãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Testing Stage1CombinedLoss Dict support...")
    
    criterion = Stage1CombinedLoss(test_config)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    pred = {
        'm1': torch.randn(2, 64, 4),
        'm5': torch.randn(2, 13, 4),
        'h1': torch.randn(2, 2, 4)
    }
    
    target = {
        'm1': torch.randn(2, 64, 4),
        'm5': torch.randn(2, 13, 4),
        'h1': torch.randn(2, 2, 4)
    }
    
    masks = {
        'm1': torch.rand(2, 64) < 0.15,
        'm5': torch.rand(2, 13) < 0.15,
        'h1': torch.rand(2, 2) < 0.15
    }
    
    # NaNãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    pred['m5'][:, 10:, :] = float('nan')
    target['m5'][:, 10:, :] = float('nan')
    pred['h1'][:, 1:, :] = float('nan')
    target['h1'][:, 1:, :] = float('nan')
    
    losses = criterion(pred, target, masks, m1_data={'m1': target['m1']})
    
    print(f"   âœ… Lossè¨ˆç®—çµæœ:")
    for loss_name, loss_value in losses.items():
        if hasattr(loss_value, 'item'):
            print(f"      {loss_name}: {loss_value.item():.6f}")
        else:
            print(f"      {loss_name}: {loss_value:.6f}")
    
    return losses

def test_integration():
    """çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Testing integration (Model v2 full pipeline)...")
    
    # 1. collate test
    collated = test_dict_collate()
    
    # 2. masking test
    masks, masked_features = test_masking_strategy_dict()
    
    # 3. model forward test
    outputs = test_model_v2_forward()
    
    # 4. loss calculation test
    losses = test_loss_dict()
    
    print("âœ… çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†!")
    return True

if __name__ == "__main__":
    print("ğŸš€ Model v2 ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    try:
        success = test_integration()
        print("\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸ! Model v2ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)