#!/usr/bin/env python3
"""
T5 Language Model Adapter for Time Series
T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«é©å¿œã•ã›ã‚‹ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from typing import Dict, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

try:
    from transformers import T5EncoderModel, T5Config
    from huggingface_hub.errors import RepositoryNotFoundError
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    T5EncoderModel = None
    T5Config = None
    RepositoryNotFoundError = OSError  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯


class PatchEmbedding(nn.Module):
    """æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒƒãƒåŒ–ã—ã¦T5äº’æ›ã®åŸ‹ã‚è¾¼ã¿ã«å¤‰æ›"""
    
    def __init__(self, 
                 n_features: int,
                 patch_len: int, 
                 d_model: int,
                 n_timeframes: int):
        super().__init__()
        self.n_features = n_features
        self.patch_len = patch_len
        self.d_model = d_model
        self.n_timeframes = n_timeframes
        
        # ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºã®ç‰¹å¾´é‡æ¬¡å…ƒ
        patch_dim = n_features * patch_len
        
        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã®æŠ•å½±å±¤
        self.patch_projections = nn.ModuleList([
            nn.Linear(patch_dim, d_model) for _ in range(n_timeframes)
        ])
        
        # ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        self.pos_embedding = nn.Parameter(torch.randn(1, 1000, d_model, dtype=torch.float32) * 0.02)
        
        # Layer normalization
        self.layer_norm = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            x: [batch, n_tf, seq_len, n_features]
        Returns:
            patches: [batch, n_tf, n_patches, d_model]
            attention_mask: [batch, n_tf, n_patches]
        """
        batch_size, n_tf, seq_len, n_features = x.shape
        
        # ãƒ‘ãƒƒãƒæ•°ã‚’è¨ˆç®—
        n_patches = seq_len // self.patch_len
        effective_len = n_patches * self.patch_len
        
        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’ãƒ‘ãƒƒãƒå¢ƒç•Œã«èª¿æ•´
        x = x[:, :, :effective_len, :]
        
        # ãƒ‘ãƒƒãƒåŒ–: [batch, n_tf, n_patches, patch_len, n_features]
        x = x.view(batch_size, n_tf, n_patches, self.patch_len, n_features)
        
        # ãƒ‘ãƒƒãƒã‚’å¹³å¦åŒ–: [batch, n_tf, n_patches, patch_dim]
        patch_dim = self.patch_len * n_features
        x = x.view(batch_size, n_tf, n_patches, patch_dim)
        
        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«æŠ•å½±
        patches = []
        for tf_idx in range(n_tf):
            tf_x = x[:, tf_idx]  # [batch, n_patches, patch_dim]
            tf_patches = self.patch_projections[tf_idx](tf_x)  # [batch, n_patches, d_model]
            patches.append(tf_patches)
        
        patches = torch.stack(patches, dim=1)  # [batch, n_tf, n_patches, d_model]
        
        # ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¿½åŠ 
        pos_emb = self.pos_embedding[:, :n_patches, :].unsqueeze(1)  # [1, 1, n_patches, d_model]
        patches = patches + pos_emb
        
        # T5äº’æ›æ­£è¦åŒ–ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        patches = self.layer_norm(patches)
        patches = patches / math.sqrt(self.d_model)  # T5æƒ³å®šåˆ†å¸ƒã«åˆã‚ã›ã‚‹
        patches = self.dropout(patches)
        
        # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ (ã™ã¹ã¦æœ‰åŠ¹)
        attention_mask = torch.ones(batch_size, n_tf, n_patches, 
                                   dtype=torch.bool, device=x.device)
        
        return patches, attention_mask


class T5TimeSeriesAdapter(nn.Module):
    """T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«é©å¿œã•ã›ã‚‹ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼"""
    
    def __init__(self, config: Dict):
        super().__init__()
        
        if not TRANSFORMERS_AVAILABLE:
            raise ImportError(
                "transformers library is required for T5 adapter. "
                "Install with: pip install transformers>=4.42.0"
            )
        
        # è¨­å®šã®æŠ½å‡º
        transfer_config = config.get('transfer_learning', {})
        self.lm_name_or_path = transfer_config.get('lm_name_or_path', 'google/t5-small')
        self.patch_len = transfer_config.get('patch_len', 16)
        self.freeze_lm_epochs = transfer_config.get('freeze_lm_epochs', 3)
        
        # ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ
        self.n_features = config['data']['n_features']
        self.n_timeframes = config['data']['n_timeframes']
        self.seq_len = config['data']['seq_len']
        
        # T5ã®è¨­å®šã‚’å–å¾—ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œï¼‰
        try:
            self.t5_config = T5Config.from_pretrained(
                self.lm_name_or_path,
                local_files_only=False,  # ã¾ãšã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚’è©¦è¡Œ
                use_auth_token=False
            )
        except (OSError, RepositoryNotFoundError) as e:
            # äº‹å‰å­¦ç¿’æ¸ˆã¿T5ãŒå¿…è¦ãªã®ã§ã€ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸã‚‰åœæ­¢
            raise RuntimeError(
                f"âŒ {self.lm_name_or_path} ã®äº‹å‰å­¦ç¿’æ¸ˆã¿é‡ã¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
                f"è»¢ç§»å­¦ç¿’ã«ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒå¿…é ˆã§ã™ã€‚\n\n"
                f"è§£æ±ºæ–¹æ³•:\n"
                f"1. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç’°å¢ƒ: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãƒ»èªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç¢ºèª\n"
                f"2. ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒ: ä»¥ä¸‹ã§ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n"
                f"   huggingface-cli download google/t5-small\n\n"
                f"å…ƒã®ã‚¨ãƒ©ãƒ¼: {e}"
            )
            
        self.d_model = self.t5_config.d_model  # é€šå¸¸512 (T5-small)
        
        # ãƒ‘ãƒƒãƒåŸ‹ã‚è¾¼ã¿å±¤
        self.patch_embedding = PatchEmbedding(
            n_features=self.n_features,
            patch_len=self.patch_len,
            d_model=self.d_model,
            n_timeframes=self.n_timeframes
        )
        
        # T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œï¼‰
        try:
            print(f"ğŸ¤— T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {self.lm_name_or_path}")
            self.t5_encoder = T5EncoderModel.from_pretrained(
                self.lm_name_or_path,
                local_files_only=False,
                use_auth_token=False
            )
        except (OSError, RepositoryNotFoundError) as e:
            # äº‹å‰å­¦ç¿’æ¸ˆã¿T5ãŒå¿…è¦ãªã®ã§ã€ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸã‚‰åœæ­¢
            raise RuntimeError(
                f"âŒ T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ {self.lm_name_or_path} ã®äº‹å‰å­¦ç¿’æ¸ˆã¿é‡ã¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
                f"è»¢ç§»å­¦ç¿’ã«ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒå¿…é ˆã§ã™ã€‚\n"
                f"å…ƒã®ã‚¨ãƒ©ãƒ¼: {e}"
            )
        
        # å‡ºåŠ›æŠ•å½±å±¤ï¼ˆT5ã®d_modelã‹ã‚‰Stage-1ã®d_modelã«å¤‰æ›ï¼‰
        stage1_d_model = config['model']['encoder']['d_model']
        self.output_projection = nn.Linear(self.d_model, stage1_d_model)
        
        # åˆæœŸåŒ–æ™‚ã¯T5éƒ¨åˆ†ã‚’å‡çµ
        self.freeze_t5_encoder()
        
        print(f"âœ… T5TimeSeriesAdapteråˆæœŸåŒ–å®Œäº†")
        print(f"   T5 d_model: {self.d_model}")
        print(f"   Stage-1 d_model: {stage1_d_model}")
        print(f"   Patch length: {self.patch_len}")
        print(f"   åˆæœŸå‡çµã‚¨ãƒãƒƒã‚¯æ•°: {self.freeze_lm_epochs}")
    
    def freeze_t5_encoder(self):
        """T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼éƒ¨åˆ†ã‚’å‡çµ"""
        for param in self.t5_encoder.parameters():
            param.requires_grad = False
        print("ğŸ”’ T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å‡çµã—ã¾ã—ãŸ")
    
    def unfreeze_t5_encoder(self):
        """T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼éƒ¨åˆ†ã®å‡çµã‚’è§£é™¤"""
        for param in self.t5_encoder.parameters():
            param.requires_grad = True
        print("ğŸ”“ T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å‡çµã‚’è§£é™¤ã—ã¾ã—ãŸ")
    
    def get_model_info(self) -> Dict:
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¿”ã™"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        t5_params = sum(p.numel() for p in self.t5_encoder.parameters())
        
        return {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            't5_parameters': t5_params,
            't5_frozen': not next(self.t5_encoder.parameters()).requires_grad,
            'model_size_mb': total_params * 4 / (1024 * 1024),  # float32ã‚’ä»®å®š
        }
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: [batch, n_tf, seq_len, n_features]
        Returns:
            encoded: [batch, n_tf, seq_len, d_model] (Stage-1äº’æ›)
        """
        batch_size, n_tf, seq_len, n_features = x.shape
        
        # ãƒ‘ãƒƒãƒåŸ‹ã‚è¾¼ã¿
        patches, attention_mask = self.patch_embedding(x)
        # patches: [batch, n_tf, n_patches, d_model]
        
        # å„ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’é©ç”¨
        encoded_patches = []
        
        for tf_idx in range(n_tf):
            tf_patches = patches[:, tf_idx]  # [batch, n_patches, d_model]
            tf_mask = attention_mask[:, tf_idx]  # [batch, n_patches]
            
            # T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã«å…¥åŠ›
            encoder_outputs = self.t5_encoder(
                inputs_embeds=tf_patches,
                attention_mask=tf_mask.to(torch.float32)
            )
            
            # æœ€å¾Œã®éš ã‚ŒçŠ¶æ…‹ã‚’å–å¾—
            encoded = encoder_outputs.last_hidden_state  # [batch, n_patches, d_model]
            encoded_patches.append(encoded)
        
        # ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ¬¡å…ƒã‚’å¾©å…ƒ
        encoded_patches = torch.stack(encoded_patches, dim=1)  # [batch, n_tf, n_patches, d_model]
        
        # ãƒ‘ãƒƒãƒã‹ã‚‰ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¾©å…ƒï¼ˆè£œé–“ï¼‰
        n_patches = encoded_patches.size(2)
        patch_seq_len = n_patches * self.patch_len
        
        if patch_seq_len != seq_len:
            # é•·ã•ãŒç•°ãªã‚‹å ´åˆã¯è£œé–“
            encoded_patches = F.interpolate(
                encoded_patches.permute(0, 1, 3, 2),  # [batch, n_tf, d_model, n_patches]
                size=seq_len,
                mode='linear',
                align_corners=False
            ).permute(0, 1, 3, 2)  # [batch, n_tf, seq_len, d_model]
        else:
            # ãƒ‘ãƒƒãƒã‚’å±•é–‹
            encoded_patches = encoded_patches.repeat_interleave(self.patch_len, dim=2)
            encoded_patches = encoded_patches[:, :, :seq_len, :]
        
        # Stage-1ã®d_modelã«æŠ•å½±
        output = self.output_projection(encoded_patches)
        
        return output


try:
    from pytorch_lightning.callbacks import Callback
    LIGHTNING_AVAILABLE = True
except ImportError:
    LIGHTNING_AVAILABLE = False
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼Callbackã‚¯ãƒ©ã‚¹
    class Callback:
        pass

class GradualUnfreezingCallback(Callback):
    """PyTorch Lightning Callback for gradual unfreezing of T5 encoder"""
    
    def __init__(self, freeze_epochs: int = 3):
        super().__init__()
        self.freeze_epochs = freeze_epochs
        self.unfrozen = False
    
    def on_train_epoch_start(self, trainer, pl_module):
        """ã‚¨ãƒãƒƒã‚¯é–‹å§‹æ™‚ã«T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å‡çµçŠ¶æ…‹ã‚’åˆ¶å¾¡"""
        current_epoch = trainer.current_epoch
        
        # T5ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if hasattr(pl_module.model, 'shared_encoder') and \
           isinstance(pl_module.model.shared_encoder, T5TimeSeriesAdapter):
            
            if current_epoch >= self.freeze_epochs and not self.unfrozen:
                pl_module.model.shared_encoder.unfreeze_t5_encoder()
                self.unfrozen = True
                print(f"ğŸ”“ ã‚¨ãƒãƒƒã‚¯{current_epoch}: T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å‡çµã‚’è§£é™¤")
            elif current_epoch < self.freeze_epochs and self.unfrozen:
                # å†å‡çµï¼ˆé€šå¸¸ã¯ç™ºç”Ÿã—ãªã„ãŒå¿µã®ãŸã‚ï¼‰
                pl_module.model.shared_encoder.freeze_t5_encoder()
                self.unfrozen = False
                print(f"ğŸ”’ ã‚¨ãƒãƒƒã‚¯{current_epoch}: T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å†å‡çµ")


def create_differential_learning_rate_groups(model, base_lr: float, t5_lr_factor: float = 0.1, 
                                          layerwise_lr_decay: float = None, t5_lr_top: float = None):
    """T5éƒ¨åˆ†ã¨ãã®ä»–ã§ç•°ãªã‚‹å­¦ç¿’ç‡ã‚’è¨­å®šã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
    
    Args:
        model: ãƒ¢ãƒ‡ãƒ«
        base_lr: ãƒ˜ãƒƒãƒ‰ & Adapter ç”¨ã®åŸºæº– LR
        t5_lr_factor: T5å­¦ç¿’ç‡ä¿‚æ•°ï¼ˆlayerwise_lr_decayãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã«ä½¿ç”¨ï¼‰
        layerwise_lr_decay: ä¸‹ä½å±¤ã»ã©LRã‚’æ¸›è¡°ã•ã›ã‚‹ä¿‚æ•°ï¼ˆä¾‹: 0.85ï¼‰
        t5_lr_top: T5æœ€ä¸Šå±¤ã®å­¦ç¿’ç‡ï¼ˆlayerwise_lr_decayã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ï¼‰
    """
    
    param_groups = []
    other_params = []
    
    if hasattr(model, 'shared_encoder') and isinstance(model.shared_encoder, T5TimeSeriesAdapter):
        t5_encoder = model.shared_encoder.t5_encoder
        
        # Layerwise LR DecayãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
        if layerwise_lr_decay is not None and t5_lr_top is not None:
            # T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ãƒ–ãƒ­ãƒƒã‚¯æ•°å–å¾—
            if hasattr(t5_encoder, 'encoder') and hasattr(t5_encoder.encoder, 'block'):
                num_layers = len(t5_encoder.encoder.block)
                
                # å„ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«ç•°ãªã‚‹å­¦ç¿’ç‡ã‚’è¨­å®š
                for i, block in enumerate(t5_encoder.encoder.block):
                    # i=0ãŒæœ€ä¸‹å±¤ã€i=num_layers-1ãŒæœ€ä¸Šå±¤
                    decay_factor = layerwise_lr_decay ** (num_layers - 1 - i)
                    lr_i = t5_lr_top * decay_factor
                    
                    param_groups.append({
                        'params': list(block.parameters()),
                        'lr': lr_i,
                        'name': f't5_block_{i}'
                    })
                
                # ãã®ä»–ã®T5ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆembedding, final_layer_normãªã©ï¼‰
                t5_block_params = {p for block in t5_encoder.encoder.block for p in block.parameters()}
                other_t5_params = [p for p in t5_encoder.parameters() if p not in t5_block_params]
                
                if other_t5_params:
                    param_groups.append({
                        'params': other_t5_params,
                        'lr': t5_lr_top,
                        'name': 't5_other'
                    })
                
                print(f"ğŸ”§ Layerwise LR Decayé©ç”¨: {num_layers}å±¤, top_lr={t5_lr_top:.2e}, decay={layerwise_lr_decay}")
                
                # æœ€ä¸‹å±¤ã¨æœ€ä¸Šå±¤ã®LRã‚’è¡¨ç¤º
                bottom_lr = t5_lr_top * (layerwise_lr_decay ** (num_layers - 1))
                print(f"   â””â”€ T5 block_0 (æœ€ä¸‹å±¤): lr={bottom_lr:.2e}")
                print(f"   â””â”€ T5 block_{num_layers-1} (æœ€ä¸Šå±¤): lr={t5_lr_top:.2e}")
                
            else:
                # ãƒ–ãƒ­ãƒƒã‚¯æ§‹é€ ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å¾“æ¥æ–¹å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                print("âš ï¸ T5ãƒ–ãƒ­ãƒƒã‚¯æ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¾“æ¥ã®å·®åˆ†å­¦ç¿’ç‡ã‚’ä½¿ç”¨")
                t5_params = [p for p in t5_encoder.parameters() if p.requires_grad]
                if t5_params:
                    param_groups.append({
                        'params': t5_params,
                        'lr': t5_lr_top,
                        'name': 'T5_encoder'
                    })
        else:
            # å¾“æ¥ã®å˜ç´”ãªå·®åˆ†å­¦ç¿’ç‡
            t5_params = [p for p in t5_encoder.parameters() if p.requires_grad]
            if t5_params:
                param_groups.append({
                    'params': t5_params,
                    'lr': base_lr * t5_lr_factor,
                    'name': 'T5_encoder'
                })
        
        # ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆT5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ä»¥å¤–ï¼‰
        t5_encoder_params = {p for p in t5_encoder.parameters()}
        for name, param in model.named_parameters():
            if param.requires_grad and param not in t5_encoder_params:
                other_params.append(param)
    else:
        # T5ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„å ´åˆã¯å…¨ã¦é€šå¸¸å­¦ç¿’ç‡
        other_params = [p for p in model.parameters() if p.requires_grad]
    
    # ãƒ˜ãƒƒãƒ‰ & Adapter ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    if other_params:
        param_groups.append({
            'params': other_params,
            'lr': base_lr,
            'name': 'head_and_adapter'
        })
    
    return param_groups