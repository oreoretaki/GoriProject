#!/usr/bin/env python3
"""
Stage 1 æå¤±é–¢æ•°
Multi-resolution STFT, Cross-TF consistency, Amplitude-Phase correlation
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class HuberLoss(nn.Module):
    """Huberæå¤±ï¼ˆTFã”ã¨ã®OHLCå†æ§‹ç¯‰ï¼‰"""
    
    def __init__(self, delta: float = 1.0):
        super().__init__()
        self.delta = delta
        
    def forward(self, pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:
        """
        Args:
            pred: [batch, n_tf, seq_len, 4] äºˆæ¸¬OHLC
            target: [batch, n_tf, seq_len, 4] æ­£è§£OHLC
            mask: [batch, n_tf, seq_len] ãƒã‚¹ã‚¯ï¼ˆ1=æå¤±è¨ˆç®—å¯¾è±¡ï¼‰
            
        Returns:
            loss: ã‚¹ã‚«ãƒ©ãƒ¼æå¤±
        """
        loss = F.huber_loss(pred, target, delta=self.delta, reduction='none')  # [batch, n_tf, seq_len, 4]
        
        if mask is not None:
            # ãƒã‚¹ã‚¯éƒ¨åˆ†ã®ã¿æå¤±è¨ˆç®—
            mask = mask.unsqueeze(-1)  # [batch, n_tf, seq_len, 1]
            loss = loss * mask
            return loss.sum() / (mask.sum() * 4 + 1e-8)
        else:
            return loss.mean()

class STFTLoss(nn.Module):
    """ãƒãƒ«ãƒè§£åƒåº¦STFTæå¤±ï¼ˆå®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, scales: List[int] = [256, 512, 1024], hop_ratio: float = 0.25):
        super().__init__()
        self.scales = scales
        self.hop_ratio = hop_ratio
        
        # ğŸ”¥ Hann windowã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
        self._hann_windows = {}
        
    def forward(self, pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:
        """
        Args:
            pred: [batch, n_tf, seq_len, 4] äºˆæ¸¬OHLC
            target: [batch, n_tf, seq_len, 4] æ­£è§£OHLC
            mask: [batch, n_tf, seq_len] ãƒã‚¹ã‚¯
            
        Returns:
            loss: STFTæå¤±
        """
        batch_size, n_tf, seq_len, n_features = pred.shape
        
        # ğŸ”¥ å®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–: [B, TF, T, F] -> [B*TF*F, T]
        pred_batched = pred.permute(0, 1, 3, 2).reshape(-1, seq_len)    # [B*TF*F, T]
        target_batched = target.permute(0, 1, 3, 2).reshape(-1, seq_len) # [B*TF*F, T]
        
        total_loss = 0.0
        
        # å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ä¸€æ‹¬STFTè¨ˆç®—ï¼ˆ13,824å› â†’ 3å›ï¼‰
        for scale in self.scales:
            if seq_len < scale:
                continue
                
            hop_length = int(scale * self.hop_ratio)
            
            # Hann windowã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—
            if scale not in self._hann_windows:
                self._hann_windows[scale] = torch.hann_window(scale, device=pred.device)
            hann_window = self._hann_windows[scale]
            
            # ğŸ”¥ ä¸€æ‹¬STFTè¨ˆç®—ï¼ˆæ•°ä¸‡å€é«˜é€ŸåŒ–ï¼‰
            with torch.cuda.amp.autocast(enabled=False):
                pred_batched_32 = pred_batched.float().cuda()
                target_batched_32 = target_batched.float().cuda()
                
                # å…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä¸€æ‹¬STFT
                pred_stft = torch.stft(
                    pred_batched_32,
                    n_fft=scale,
                    hop_length=hop_length,
                    window=hann_window,
                    return_complex=True
                )
                target_stft = torch.stft(
                    target_batched_32,
                    n_fft=scale,
                    hop_length=hop_length, 
                    window=hann_window,
                    return_complex=True
                )
            
            # ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰æå¤±ï¼ˆä¸€æ‹¬è¨ˆç®—ï¼‰
            pred_mag = torch.abs(pred_stft)
            target_mag = torch.abs(target_stft)
            mag_loss = F.l1_loss(pred_mag, target_mag)
            
            # ä½ç›¸æå¤±ï¼ˆä¸€æ‹¬è¨ˆç®—ï¼‰
            phase_loss = F.l1_loss(pred_stft.real, target_stft.real) + \
                        F.l1_loss(pred_stft.imag, target_stft.imag)
            
            total_loss += mag_loss + 0.1 * phase_loss
        
        # æ­£è¦åŒ–
        return total_loss / max(len(self.scales), 1)

class CrossTFConsistencyLoss(nn.Module):
    """ã‚¯ãƒ­ã‚¹TFæ•´åˆæ€§æå¤±ï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰TF vs M1é›†ç´„ï¼‰"""
    
    def __init__(self):
        super().__init__()
        
    def forward(self, pred: torch.Tensor, m1_data: torch.Tensor) -> torch.Tensor:
        """
        Args:
            pred: [batch, n_tf, seq_len, 4] äºˆæ¸¬ã•ã‚ŒãŸãƒãƒ«ãƒTF OHLC
            m1_data: [batch, seq_len, 4] M1 OHLCï¼ˆãƒ™ãƒ¼ã‚¹ï¼‰
            
        Returns:
            loss: ã‚¯ãƒ­ã‚¹TFæ•´åˆæ€§æå¤±
        """
        batch_size, n_tf, seq_len, _ = pred.shape
        total_loss = 0.0
        
        # M1ã¯ pred[:, 0] ã¨ä»®å®š
        pred_m1 = pred[:, 0]  # [batch, seq_len, 4]
        
        # å„ä¸Šä½TFã«ã¤ã„ã¦ã€å¯¾å¿œã™ã‚‹M1é›†ç´„ã¨æ¯”è¼ƒ
        tf_intervals = {1: 5, 2: 15, 3: 30, 4: 60, 5: 240}  # M5, M15, M30, H1, H4ã®é–“éš”ï¼ˆåˆ†ï¼‰
        
        for tf_idx in range(1, min(n_tf, 6)):  # M5ä»¥ä¸Šã®TFã«ã¤ã„ã¦
            if tf_idx not in tf_intervals:
                continue
                
            interval = tf_intervals[tf_idx]
            pred_tf = pred[:, tf_idx]  # [batch, seq_len, 4]
            
            # M1ã‹ã‚‰æœŸå¾…ã•ã‚Œã‚‹é›†ç´„å€¤ã‚’è¨ˆç®—
            expected_tf = self._aggregate_m1_to_tf(m1_data, interval, seq_len)
            
            # MSEæå¤±
            tf_loss = F.mse_loss(pred_tf, expected_tf)
            total_loss += tf_loss
            
        return total_loss / max(1, min(n_tf - 1, 5))
        
    def _aggregate_m1_to_tf(self, m1_data: torch.Tensor, interval: int, target_len: int) -> torch.Tensor:
        """
        M1ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šé–“éš”ã§é›†ç´„ã—ã¦TFãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼ˆå®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼‰
        
        Args:
            m1_data: [batch, seq_len, 4] M1 OHLC
            interval: é›†ç´„é–“éš”
            target_len: å‡ºåŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
            
        Returns:
            aggregated: [batch, target_len, 4] é›†ç´„æ¸ˆã¿OHLC
        """
        batch_size, seq_len, _ = m1_data.shape
        
        # ç°¡æ˜“é›†ç´„ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šç²¾å¯†ãªå®Ÿè£…ãŒå¿…è¦ï¼‰
        if interval >= seq_len:
            # å…¨æœŸé–“é›†ç´„
            open_val = m1_data[:, 0, 0:1]  # æœ€åˆã®å§‹å€¤
            high_val = m1_data[:, :, 1].max(dim=1, keepdim=True)[0]  # æœ€é«˜å€¤
            low_val = m1_data[:, :, 2].min(dim=1, keepdim=True)[0]  # æœ€å®‰å€¤
            close_val = m1_data[:, -1, 3:4]  # æœ€å¾Œã®çµ‚å€¤
            
            aggregated_bar = torch.cat([open_val, high_val, low_val, close_val], dim=1)
            return aggregated_bar.unsqueeze(1).expand(-1, target_len, -1)
        else:
            # ğŸ”¥ å®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–åŒºé–“é›†ç´„ï¼ˆPythonãƒ«ãƒ¼ãƒ—é™¤å»ï¼‰
            n_chunks = target_len
            chunk_size = seq_len // n_chunks
            
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦chunk_sizeã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            padded_len = n_chunks * chunk_size
            if padded_len < seq_len:
                # å¿…è¦ã«å¿œã˜ã¦æœ«å°¾ã‚’åˆ‡ã‚Šè©°ã‚
                m1_data = m1_data[:, :padded_len]
            elif padded_len > seq_len:
                # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆæœ€å¾Œã®å€¤ã§åŸ‹ã‚ã‚‹ï¼‰
                last_vals = m1_data[:, -1:].expand(-1, padded_len - seq_len, -1)
                m1_data = torch.cat([m1_data, last_vals], dim=1)
            
            # ğŸ”¥ [batch, seq_len, 4] -> [batch, n_chunks, chunk_size, 4]
            reshaped = m1_data.view(batch_size, n_chunks, chunk_size, 4)
            
            # ğŸ”¥ ä¸€æ‹¬OHLCé›†ç´„ï¼ˆtorch.amax/aminä½¿ç”¨ï¼‰
            open_val = reshaped[:, :, 0, 0]   # [batch, n_chunks] - å„ãƒãƒ£ãƒ³ã‚¯ã®æœ€åˆã®å§‹å€¤
            high_val = torch.amax(reshaped[:, :, :, 1], dim=2)  # [batch, n_chunks] - æœ€é«˜å€¤
            low_val = torch.amin(reshaped[:, :, :, 2], dim=2)   # [batch, n_chunks] - æœ€å®‰å€¤
            close_val = reshaped[:, :, -1, 3]  # [batch, n_chunks] - å„ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¾Œã®çµ‚å€¤
            
            # [batch, n_chunks, 4]ã«å†æ§‹æˆ
            aggregated = torch.stack([open_val, high_val, low_val, close_val], dim=2)
            
            return aggregated

class AmplitudePhaseCorrelationLoss(nn.Module):
    """æŒ¯å¹…ãƒ»ä½ç›¸ç›¸é–¢æå¤±"""
    
    def __init__(self):
        super().__init__()
        
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        Args:
            pred: [batch, n_tf, seq_len, 4] äºˆæ¸¬OHLC
            target: [batch, n_tf, seq_len, 4] æ­£è§£OHLC
            
        Returns:
            loss: æŒ¯å¹…ãƒ»ä½ç›¸ç›¸é–¢æå¤±
        """
        batch_size, n_tf, seq_len, n_features = pred.shape
        
        # ğŸ”¥ å®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–: [B, TF, T, F] -> [B*TF*F, T]
        pred_batched = pred.permute(0, 1, 3, 2).reshape(-1, seq_len)    # [B*TF*F, T]
        target_batched = target.permute(0, 1, 3, 2).reshape(-1, seq_len) # [B*TF*F, T]
        
        # ğŸ”¥ ä¸€æ‹¬FFTè¨ˆç®—ï¼ˆ24å› â†’ 1å›ï¼‰
        with torch.cuda.amp.autocast(enabled=False):
            pred_batched_32 = pred_batched.float().cuda()
            target_batched_32 = target_batched.float().cuda()
            
            pred_fft = torch.fft.fft(pred_batched_32, dim=-1)
            target_fft = torch.fft.fft(target_batched_32, dim=-1)
        
        # æŒ¯å¹…ãƒ»ä½ç›¸ã‚’ä¸€æ‹¬è¨ˆç®—
        pred_amp = torch.abs(pred_fft)
        target_amp = torch.abs(target_fft)
        pred_phase = torch.angle(pred_fft)
        target_phase = torch.angle(target_fft)
        
        # ç›¸é–¢æå¤±ã‚’ä¸€æ‹¬è¨ˆç®—
        amp_corr = self._correlation_loss(pred_amp, target_amp)
        phase_corr = self._correlation_loss(pred_phase, target_phase)
        
        total_loss = amp_corr + phase_corr
        
        return total_loss
        
    def _correlation_loss(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
        """ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°ã®è² å€¤ã‚’æå¤±ã¨ã—ã¦è¨ˆç®—"""
        
        # å¹³å‡é™¤å»
        x_centered = x - x.mean(dim=-1, keepdim=True)
        y_centered = y - y.mean(dim=-1, keepdim=True)
        
        # ç›¸é–¢ä¿‚æ•°è¨ˆç®—
        numerator = (x_centered * y_centered).sum(dim=-1)
        x_std = torch.sqrt((x_centered ** 2).sum(dim=-1) + 1e-8)
        y_std = torch.sqrt((y_centered ** 2).sum(dim=-1) + 1e-8)
        
        correlation = numerator / (x_std * y_std + 1e-8)
        
        # ç›¸é–¢ãŒé«˜ã„ã»ã©æå¤±ãŒå°ã•ããªã‚‹ã‚ˆã†ã«è² å€¤ã‚’è¿”ã™
        return (1 - correlation).mean()

class Stage1CombinedLoss(nn.Module):
    """Stage 1 çµ±åˆæå¤±é–¢æ•°"""
    
    def __init__(self, config: dict):
        super().__init__()
        
        # æå¤±é‡ã¿
        self.weights = config['loss']['weights']
        
        # å€‹åˆ¥æå¤±é–¢æ•°
        self.huber_loss = HuberLoss(delta=config['loss']['huber_delta'])
        self.stft_loss = STFTLoss(scales=config['loss']['stft_scales'])
        self.cross_loss = CrossTFConsistencyLoss()
        self.amp_phase_loss = AmplitudePhaseCorrelationLoss()
        
        print(f"ğŸ¯ Stage1CombinedLossåˆæœŸåŒ–")
        print(f"   æå¤±é‡ã¿: {self.weights}")
        
    def forward(
        self, 
        pred, 
        target, 
        masks,
        m1_data = None
    ) -> Dict[str, torch.Tensor]:
        """
        Args:
            pred: [batch, n_tf, seq_len, 4] äºˆæ¸¬OHLC ã¾ãŸã¯ Dict[str, torch.Tensor]
            target: [batch, n_tf, seq_len, 4] æ­£è§£OHLC ã¾ãŸã¯ Dict[str, torch.Tensor]
            masks: [batch, n_tf, seq_len] ãƒã‚¹ã‚¯ ã¾ãŸã¯ Dict[str, torch.Tensor]
            m1_data: [batch, seq_len, 4] M1ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¯ãƒ­ã‚¹æå¤±ç”¨ï¼‰ã¾ãŸã¯ Dict[str, torch.Tensor]
            
        Returns:
            losses: {
                'total': ç·æå¤±,
                'recon_tf': Huberæå¤±,
                'spec_tf': STFTæå¤±,
                'cross': ã‚¯ãƒ­ã‚¹æ•´åˆæ€§æå¤±,
                'amp_phase': æŒ¯å¹…ä½ç›¸æå¤±
            }
        """
        # Dict format support for Model v2
        if isinstance(pred, dict):
            return self._forward_dict(pred, target, masks, m1_data)
        
        # Legacy tensor format support
        
        # å„æå¤±è¨ˆç®—
        recon_loss = self.huber_loss(pred, target, masks)
        spec_loss = self.stft_loss(pred, target, masks)
        amp_phase_loss = self.amp_phase_loss(pred, target)
        
        # ã‚¯ãƒ­ã‚¹æå¤±ï¼ˆM1ãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰
        if m1_data is not None:
            cross_loss = self.cross_loss(pred, m1_data)
        else:
            cross_loss = torch.tensor(0.0, device=pred.device)
            
        # é‡ã¿ä»˜ãç·æå¤±
        total_loss = (
            self.weights['recon_tf'] * recon_loss +
            self.weights['spec_tf'] * spec_loss +
            self.weights['cross'] * cross_loss +
            self.weights['amp_phase'] * amp_phase_loss
        )
        
        return {
            'total': total_loss,
            'recon_tf': recon_loss,
            'spec_tf': spec_loss, 
            'cross': cross_loss,
            'amp_phase': amp_phase_loss
        }
    
    def _forward_dict(
        self,
        pred: Dict[str, torch.Tensor],
        target: Dict[str, torch.Tensor], 
        masks: Dict[str, torch.Tensor],
        m1_data: Dict[str, torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        Dictå½¢å¼ã®å…¥åŠ›ã«å¯¾ã™ã‚‹æå¤±è¨ˆç®— (Model v2ç”¨)
        
        Args:
            pred: Dict[tf_name, torch.Tensor] - å„TFã®äºˆæ¸¬ [batch, seq_len, 4]
            target: Dict[tf_name, torch.Tensor] - å„TFã®æ­£è§£ [batch, seq_len, 4]
            masks: Dict[tf_name, torch.Tensor] - å„TFã®ãƒã‚¹ã‚¯ [batch, seq_len]
            m1_data: Dict[tf_name, torch.Tensor] - M1ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¯ãƒ­ã‚¹æå¤±ç”¨ï¼‰
            
        Returns:
            losses: Dict[str, torch.Tensor] - å„æå¤±ã®è¾æ›¸
        """
        device = list(pred.values())[0].device
        
        # å„æå¤±è¨ˆç®—
        recon_loss = self._huber_loss_dict(pred, target, masks)
        spec_loss = self._stft_loss_dict(pred, target, masks)
        amp_phase_loss = self._amp_phase_loss_dict(pred, target)
        
        # ã‚¯ãƒ­ã‚¹æå¤±ï¼ˆM1ãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚ŒãŸå ´åˆã®ã¿ï¼‰
        if m1_data is not None and 'm1' in pred:
            cross_loss = self._cross_loss_dict(pred, m1_data)
        elif 'm1' in pred:
            # ğŸ”¥ å …ç‰¢åŒ–: M1ãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¦ã„ãªã„ãŒã€M1äºˆæ¸¬ãŒã‚ã‚‹å ´åˆ
            # predã®M1ã‚’detachã—ã¦m1_dataã¨ã—ã¦ä½¿ç”¨
            m1_fallback = {'m1': pred['m1'].detach()}
            cross_loss = self._cross_loss_dict(pred, m1_fallback)
        else:
            cross_loss = torch.tensor(0.0, device=device)
            
        # é‡ã¿ä»˜ãç·æå¤±
        total_loss = (
            self.weights['recon_tf'] * recon_loss +
            self.weights['spec_tf'] * spec_loss +
            self.weights['cross'] * cross_loss +
            self.weights['amp_phase'] * amp_phase_loss
        )
        
        return {
            'total': total_loss,
            'recon_tf': recon_loss,
            'spec_tf': spec_loss, 
            'cross': cross_loss,
            'amp_phase': amp_phase_loss
        }
    
    def _huber_loss_dict(self, pred: Dict[str, torch.Tensor], target: Dict[str, torch.Tensor], masks: Dict[str, torch.Tensor]) -> torch.Tensor:
        """Dictå½¢å¼ã®Huberæå¤±è¨ˆç®—"""
        total_loss = 0.0
        total_count = 0
        
        for tf_name, pred_tf in pred.items():
            if tf_name not in target:
                continue
                
            target_tf = target[tf_name]
            mask_tf = masks.get(tf_name, None) if masks is not None else None
            
            # NaNå€¤ã‚’é™¤å¤–ï¼ˆpaddingå¯¾å¿œï¼‰
            batch_size_tf, seq_len_tf = pred_tf.shape[:2]
            valid_mask = ~torch.isnan(pred_tf[..., 0])  # [batch, seq_len_tf]
            
            if mask_tf is not None:
                # mask_tfãŒvalid_maskã¨åŒã˜shapeã§ãªã„å ´åˆã¯èª¿æ•´
                if mask_tf.shape != valid_mask.shape:
                    # mask_tfã‚’target_tfã®å®Ÿéš›ã®å½¢çŠ¶ã«åˆã‚ã›ã‚‹
                    if mask_tf.shape[1] > seq_len_tf:
                        mask_tf = mask_tf[:, :seq_len_tf]  # truncate
                    elif mask_tf.shape[1] < seq_len_tf:
                        # padding with False (not masked)
                        pad_width = seq_len_tf - mask_tf.shape[1]
                        mask_tf = torch.cat([mask_tf, torch.zeros(batch_size_tf, pad_width, dtype=torch.bool, device=mask_tf.device)], dim=1)
                
                valid_mask = valid_mask & ~mask_tf  # ãƒã‚¹ã‚¯ã•ã‚ŒãŸä½ç½®ã‚‚é™¤å¤–
            
            if valid_mask.sum() == 0:
                continue
                
            # æœ‰åŠ¹ãªä½ç½®ã®ã¿ã§æå¤±è¨ˆç®—ï¼ˆpred ã¨ target ã¯åŒã˜é•·ã•ã§æ¥ã‚‹å‰æï¼‰
            nan_mask = ~torch.isnan(target_tf).any(dim=-1)  # [batch, seq_len_tf]
            
            # æœ‰åŠ¹ãªä½ç½®ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if nan_mask.sum() == 0:
                continue
                
            pred_valid = pred_tf[nan_mask]  # [valid_positions, 4]
            target_valid = target_tf[nan_mask]  # [valid_positions, 4]
            
            loss = F.huber_loss(pred_valid, target_valid, delta=self.huber_loss.delta, reduction='mean')
            total_loss += loss
            total_count += 1
            
        return total_loss / max(total_count, 1)
    
    def _stft_loss_dict(self, pred: Dict[str, torch.Tensor], target: Dict[str, torch.Tensor], masks: Dict[str, torch.Tensor]) -> torch.Tensor:
        """Dictå½¢å¼ã®STFTæå¤±è¨ˆç®—ï¼ˆé«˜é€ŸãƒãƒƒãƒåŒ–ç‰ˆï¼‰"""
        # ğŸ”¥ å…¨TFãƒ»å…¨ç‰¹å¾´é‡ã‚’ä¸€æ‹¬å‡¦ç†ã™ã‚‹é«˜é€Ÿå®Ÿè£…
        all_pred_seqs = []
        all_target_seqs = []
        
        # 1) å…¨ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆãƒ«ãƒ¼ãƒ—ã¯ãƒ‡ãƒ¼ã‚¿åé›†ã®ã¿ï¼‰
        for tf_name, pred_tf in pred.items():
            if tf_name not in target:
                continue
                
            target_tf = target[tf_name]
            batch_size, seq_len, n_features = pred_tf.shape
            
            # NaNå€¤ã‚’é™¤å¤–ï¼ˆpaddingå¯¾å¿œï¼‰
            valid_mask = ~torch.isnan(pred_tf[..., 0])  # [batch, seq_len]
            
            # å…¨ç‰¹å¾´é‡ã‚’ä¸€æ‹¬åé›†
            for feat_idx in range(n_features):
                # [batch, seq_len] -> æœ‰åŠ¹éƒ¨åˆ†ã®ã¿æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ 
                pred_feat = pred_tf[:, :, feat_idx]
                target_feat = target_tf[:, :, feat_idx]
                
                # æœ‰åŠ¹ãªéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡ºï¼ˆãƒãƒƒãƒå…¨ä½“ï¼‰
                if valid_mask.any():
                    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦åŒã˜é•·ã•ã«æƒãˆã‚‹ï¼ˆæœ€å¤§seq_lenï¼‰
                    all_pred_seqs.append(pred_feat)
                    all_target_seqs.append(target_feat)
        
        if not all_pred_seqs:
            return torch.tensor(0.0, device=pred.device)
        
        # 2) å…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒãƒƒãƒåŒ– [total_seqs, max_seq_len]
        pred_batch = torch.stack(all_pred_seqs, dim=0)
        target_batch = torch.stack(all_target_seqs, dim=0)
        
        total_loss = 0.0
        
        # 3) å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ä¸€æ‹¬STFTè¨ˆç®—
        for scale in self.stft_loss.scales:
            if pred_batch.shape[1] < scale:
                continue
                
            hop_length = int(scale * self.stft_loss.hop_ratio)
            
            # ğŸ”¥ ãƒãƒƒãƒåŒ–STFTï¼ˆ36,864å› â†’ 2å›ï¼‰
            with torch.cuda.amp.autocast(enabled=False):
                pred_batch_32 = pred_batch.float().cuda()
                target_batch_32 = target_batch.float().cuda()
                
                # ä¸€æ‹¬STFTè¨ˆç®—
                pred_stft = torch.stft(
                    pred_batch_32.reshape(-1, pred_batch_32.shape[-1]),  # [batch*features, seq_len]
                    n_fft=scale,
                    hop_length=hop_length,
                    return_complex=True
                )
                target_stft = torch.stft(
                    target_batch_32.reshape(-1, target_batch_32.shape[-1]),
                    n_fft=scale,
                    hop_length=hop_length,
                    return_complex=True
                )
            
            # ãƒã‚°ãƒ‹ãƒãƒ¥ãƒ¼ãƒ‰æå¤±
            pred_mag = torch.abs(pred_stft)
            target_mag = torch.abs(target_stft)
            mag_loss = F.l1_loss(pred_mag, target_mag)
            
            # ä½ç›¸æå¤±
            phase_loss = F.l1_loss(pred_stft.real, target_stft.real) + \
                        F.l1_loss(pred_stft.imag, target_stft.imag)
            
            total_loss += mag_loss + 0.1 * phase_loss
        
        # æ­£è¦åŒ–
        return total_loss / max(len(self.stft_loss.scales), 1)
    
    def _amp_phase_loss_dict(self, pred: Dict[str, torch.Tensor], target: Dict[str, torch.Tensor]) -> torch.Tensor:
        """Dictå½¢å¼ã®æŒ¯å¹…ä½ç›¸æå¤±è¨ˆç®—"""
        total_loss = 0.0
        total_count = 0
        
        for tf_name, pred_tf in pred.items():
            if tf_name not in target:
                continue
                
            target_tf = target[tf_name]
            batch_size, seq_len, n_features = pred_tf.shape
            
            # NaNå€¤ã‚’é™¤å¤–ï¼ˆpaddingå¯¾å¿œï¼‰
            batch_size_tf, seq_len_tf = pred_tf.shape[:2]
            valid_mask = ~torch.isnan(pred_tf[..., 0])  # [batch, seq_len_tf]
            
            for feat_idx in range(n_features):
                pred_signal = pred_tf[:, :, feat_idx]  # [batch, seq_len]
                target_signal = target_tf[:, :, feat_idx]  # [batch, seq_len]
                
                # å„ãƒãƒƒãƒã§æœ‰åŠ¹ãªéƒ¨åˆ†ã®ã¿å–å¾—
                for b in range(batch_size):
                    valid_positions = valid_mask[b]
                    if valid_positions.sum() == 0:
                        continue
                        
                    pred_seq = pred_signal[b, valid_positions]  # [valid_len]
                    target_seq = target_signal[b, valid_positions]  # [valid_len]
                    
                    if len(pred_seq) < 8:  # FFTè¨ˆç®—ã«å¿…è¦ãªæœ€å°é•·
                        continue
                        
                    # FFTè¨ˆç®—ï¼ˆBF16å¯¾å¿œ: å¿…ãšFP32/CUDAã§å®Ÿè¡Œï¼‰
                    with torch.cuda.amp.autocast(enabled=False):  # BF16â†’FP32 autocastç„¡åŠ¹åŒ–
                        pred_seq_32 = pred_seq.float().cuda()
                        target_seq_32 = target_seq.float().cuda()
                        pred_fft = torch.fft.fft(pred_seq_32)
                        target_fft = torch.fft.fft(target_seq_32)
                    
                    # æŒ¯å¹…ãƒ»ä½ç›¸
                    pred_amp = torch.abs(pred_fft)
                    target_amp = torch.abs(target_fft)
                    pred_phase = torch.angle(pred_fft)
                    target_phase = torch.angle(target_fft)
                    
                    # ç›¸é–¢æå¤±
                    amp_corr = self.amp_phase_loss._correlation_loss(pred_amp.unsqueeze(0), target_amp.unsqueeze(0))
                    phase_corr = self.amp_phase_loss._correlation_loss(pred_phase.unsqueeze(0), target_phase.unsqueeze(0))
                    
                    total_loss += amp_corr + phase_corr
                    total_count += 1
                    
        return total_loss / max(total_count, 1)
    
    def _cross_loss_dict(self, pred: Dict[str, torch.Tensor], m1_data: Dict[str, torch.Tensor]) -> torch.Tensor:
        """Dictå½¢å¼ã®ã‚¯ãƒ­ã‚¹æ•´åˆæ€§æå¤±è¨ˆç®—"""
        if 'm1' not in pred or 'm1' not in m1_data:
            return torch.tensor(0.0, device=list(pred.values())[0].device)
            
        pred_m1 = pred['m1']  # [batch, seq_len, 4]
        m1_ref = m1_data['m1']  # [batch, seq_len, 4]
        
        total_loss = 0.0
        total_count = 0
        
        # M1ä»¥å¤–ã®TFã«ã¤ã„ã¦ã€å¯¾å¿œã™ã‚‹M1é›†ç´„ã¨æ¯”è¼ƒ
        tf_intervals = {'m5': 5, 'm15': 15, 'm30': 30, 'h1': 60, 'h4': 240}
        
        for tf_name, pred_tf in pred.items():
            if tf_name == 'm1' or tf_name not in tf_intervals:
                continue
                
            interval = tf_intervals[tf_name]
            
            # M1ã‹ã‚‰æœŸå¾…ã•ã‚Œã‚‹é›†ç´„å€¤ã‚’è¨ˆç®—
            expected_tf = self._aggregate_m1_to_tf_dict(m1_ref, interval, pred_tf.shape[1])
            
            # NaNå€¤ã‚’é™¤å¤–
            batch_size_tf, seq_len_tf = pred_tf.shape[:2]
            valid_mask = ~torch.isnan(pred_tf[..., 0])  # [batch, seq_len_tf]
            
            # expected_tfã®å½¢çŠ¶ã‚’pred_tfã«åˆã‚ã›ã‚‹
            if expected_tf.shape[1] != seq_len_tf:
                if expected_tf.shape[1] > seq_len_tf:
                    expected_tf = expected_tf[:, :seq_len_tf]  # truncate
                elif expected_tf.shape[1] < seq_len_tf:
                    # padding with NaN
                    pad_width = seq_len_tf - expected_tf.shape[1]
                    pad_tensor = torch.full((batch_size_tf, pad_width, 4), float('nan'), device=expected_tf.device, dtype=expected_tf.dtype)
                    expected_tf = torch.cat([expected_tf, pad_tensor], dim=1)
            
            if valid_mask.sum() == 0:
                continue
                
            # æœ‰åŠ¹ãªä½ç½®ã®ã¿ã§æå¤±è¨ˆç®—
            pred_valid = pred_tf[valid_mask]  # [valid_positions, 4]
            expected_valid = expected_tf[valid_mask]  # [valid_positions, 4]
            
            tf_loss = F.mse_loss(pred_valid, expected_valid)
            total_loss += tf_loss
            total_count += 1
            
        return total_loss / max(total_count, 1)
    
    def _aggregate_m1_to_tf_dict(self, m1_data: torch.Tensor, interval: int, target_len: int) -> torch.Tensor:
        """
        Dictå½¢å¼ã®M1ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šé–“éš”ã§é›†ç´„
        
        Args:
            m1_data: [batch, seq_len, 4] M1 OHLC
            interval: é›†ç´„é–“éš”
            target_len: å‡ºåŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
            
        Returns:
            aggregated: [batch, target_len, 4] é›†ç´„æ¸ˆã¿OHLC
        """
        # staticmethodç‰ˆã‚’ç›´æ¥å®Ÿè£…ï¼ˆå†å¸°å›é¿ï¼‰
        return self._aggregate_m1_to_tf_static(m1_data, interval, target_len)
    
    @staticmethod
    def _aggregate_m1_to_tf_static(m1_data: torch.Tensor, interval: int, target_len: int) -> torch.Tensor:
        """
        M1ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šé–“éš”ã§é›†ç´„ï¼ˆå®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–staticç‰ˆï¼‰
        """
        batch_size, seq_len, _ = m1_data.shape
        
        # ç°¡æ˜“é›†ç´„ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šç²¾å¯†ãªå®Ÿè£…ãŒå¿…è¦ï¼‰
        if interval >= seq_len:
            # å…¨æœŸé–“é›†ç´„
            open_val = m1_data[:, 0, 0:1]  # æœ€åˆã®å§‹å€¤
            high_val = m1_data[:, :, 1].max(dim=1, keepdim=True)[0]  # æœ€é«˜å€¤
            low_val = m1_data[:, :, 2].min(dim=1, keepdim=True)[0]  # æœ€å®‰å€¤
            close_val = m1_data[:, -1, 3:4]  # æœ€å¾Œã®çµ‚å€¤
            
            aggregated_bar = torch.cat([open_val, high_val, low_val, close_val], dim=1)
            return aggregated_bar.unsqueeze(1).expand(-1, target_len, -1)
        else:
            # ğŸ”¥ å®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–åŒºé–“é›†ç´„ï¼ˆPythonãƒ«ãƒ¼ãƒ—é™¤å»ï¼‰
            n_chunks = target_len
            chunk_size = seq_len // n_chunks
            
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦chunk_sizeã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            padded_len = n_chunks * chunk_size
            if padded_len < seq_len:
                # å¿…è¦ã«å¿œã˜ã¦æœ«å°¾ã‚’åˆ‡ã‚Šè©°ã‚
                m1_data = m1_data[:, :padded_len]
            elif padded_len > seq_len:
                # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆæœ€å¾Œã®å€¤ã§åŸ‹ã‚ã‚‹ï¼‰
                last_vals = m1_data[:, -1:].expand(-1, padded_len - seq_len, -1)
                m1_data = torch.cat([m1_data, last_vals], dim=1)
            
            # ğŸ”¥ [batch, seq_len, 4] -> [batch, n_chunks, chunk_size, 4]
            reshaped = m1_data.view(batch_size, n_chunks, chunk_size, 4)
            
            # ğŸ”¥ ä¸€æ‹¬OHLCé›†ç´„ï¼ˆtorch.amax/aminä½¿ç”¨ï¼‰
            open_val = reshaped[:, :, 0, 0]   # [batch, n_chunks] - å„ãƒãƒ£ãƒ³ã‚¯ã®æœ€åˆã®å§‹å€¤
            high_val = torch.amax(reshaped[:, :, :, 1], dim=2)  # [batch, n_chunks] - æœ€é«˜å€¤
            low_val = torch.amin(reshaped[:, :, :, 2], dim=2)   # [batch, n_chunks] - æœ€å®‰å€¤
            close_val = reshaped[:, :, -1, 3]  # [batch, n_chunks] - å„ãƒãƒ£ãƒ³ã‚¯ã®æœ€å¾Œã®çµ‚å€¤
            
            # [batch, n_chunks, 4]ã«å†æ§‹æˆ
            aggregated = torch.stack([open_val, high_val, low_val, close_val], dim=2)
            
            return aggregated