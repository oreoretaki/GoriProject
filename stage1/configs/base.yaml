# Stage 1 Multi-TF Self-Supervised Reconstruction - Base Configuration

# データ設定
data:
  seq_len: 200                    # M1バーでのシーケンス長（≈3.3時間）
  n_timeframes: 6                 # TF数 (M1, M5, M15, M30, H1, H4, D)
  n_features: 6                   # 特徴量数 [open, high, low, close, Δclose, %body]
  total_channels: 36              # 6特徴量 × 6TF = 36チャンネル
  timeframes:
    - m1
    - m5  
    - m15
    - m30
    - h1
    - h4
    - d
  data_dir: "../data/derived"
  stats_file: "stats.json"        # 正規化統計

# マスキング設定
masking:
  mask_ratio: 0.15                # TFごとに15%のトークンをマスク
  mask_span_min: 5                # 最小マスクスパン（M1バー）
  mask_span_max: 60               # 最大マスクスパン（M1バー）
  sync_across_tf: true            # TF間でマスキング同期

# 正規化設定
normalization:
  method: "zscore"                # z-score正規化
  per_tf: true                    # TFごとに個別統計

# モデルアーキテクチャ
model:
  # TF固有ステム
  tf_stem:
    kernel_size: 3                # 1D depth-wise CNN
    d_model: 128                  # 投影次元
    
  # クロススケールミキサー  
  encoder:
    n_layers: 8                   # Mamba-TSブロック数
    d_model: 128
    d_state: 16                   # Mamba状態次元
    d_conv: 4                     # 畳み込み次元
    expand: 2                     # FFN拡張率
    cross_attn_every: 2           # 2層ごとにクロススケール注意
    flash_attn: true              # FlashAttention-2使用
    
  # Bottleneck
  bottleneck:
    latent_len: 50                # seq_len/4 = 200/4
    stride: 4                     # ストライド畳み込み
    
  # デコーダー
  decoder:
    n_layers: 4                   # 軽量デコーダー
    kernel_size: 3                # 転置畳み込み
    
  # 位置エンコーディング
  positional:
    intra_tf: "rotary"            # TF内: 学習済みRotary
    inter_tf: "learned"           # TF間: 相対時間フレームID

# 損失設定
loss:
  weights:
    recon_tf: 0.6                 # Huber損失（TFごとのOHLC）
    spec_tf: 0.2                  # マルチ解像度STFT損失
    cross: 0.15                   # クロスTF整合性損失
    amp_phase: 0.05               # 振幅・位相相関損失
    
  huber_delta: 1.0                # Huber損失のデルタ
  stft_scales: [256, 512, 1024]   # STFT解像度
  
# 訓練設定
training:
  batch_size: 24                  # 24ウィンドウ（4,800 M1バー）
  epochs: 40
  early_stop:
    patience: 5                   # 5エポック
    min_delta: 0.001              # Δcorr閾値
    
  # オプティマイザー
  optimizer:
    name: "AdamW"
    betas: [0.9, 0.98]
    weight_decay: 0.01
    
  # 学習率スケジューラー
  scheduler:
    name: "OneCycleLR"
    max_lr: 5.0e-4                # ピーク学習率
    div_factor: 3.33              # 初期LR = max_lr/div_factor = 1.5e-4
    final_div_factor: 50          # 最終LR = max_lr/final_div_factor = 1e-5
    pct_start: 0.3                # ピークまでの割合
    
  # 混合精度・勾配設定
  precision: "bf16"               # BFloat16
  gradient_clip: 1.0              # 勾配クリッピング
  accumulate_grad_batches: 1      # 勾配累積

# データ拡張
augmentation:
  ddim_noise:
    probability: 0.3
    sigma: 0.01
  time_warp:
    probability: 0.2
    sigma: 0.2
  regime_mix:
    probability: 0.1
    
# 検証・メトリクス
validation:
  val_split: 0.2                  # 20%を検証用
  metrics:
    - "correlation_per_tf"        # TFごとの相関
    - "consistency_ratio"         # 整合性比率
    - "spectral_delta"            # スペクトラムΔ
    
# ログ・チェックポイント
logging:
  log_every_n_steps: 100
  checkpoint_every_n_epochs: 5
  save_top_k: 3                   # 上位3モデル保存
  monitor: "val_correlation_mean"  # 監視メトリクス
  
# 実行設定
runtime:
  seed: 42
  num_workers: 4                  # データローダーワーカー数
  pin_memory: true
  persistent_workers: true