# Stage 1 Production Configuration - 本番学習用
# 高品質な最終モデル訓練のための設定

# データ設定
data:
  seq_len: 128                    # 本番用長期シーケンス（2の累乗）
  n_timeframes: 7                 # 全TF使用 (M1, M5, M15, M30, H1, H4, D)
  n_features: 6                   # 特徴量数 [open, high, low, close, Δclose, %body]
  total_channels: 42              # 6特徴量 × 7TF = 42チャンネル
  timeframes:
    - m1
    - m5  
    - m15
    - m30
    - h1
    - h4
    - d                           # Dailyも本番では使用
  data_dir: "../data/derived"
  stats_file: "stats.json"        # 正規化統計

# マスキング設定
masking:
  mask_ratio: 0.15                # TFごとに15%のトークンをマスク
  mask_span_min: 5                # 最小マスクスパン
  mask_span_max: 32               # 最大マスクスパン（seq_len/4）
  sync_across_tf: true            # TF間でマスキング同期

# 正規化設定
normalization:
  method: "zscore"                # z-score正規化
  per_tf: true                    # TFごとに個別統計

# モデルアーキテクチャ（本番用：高品質）
model:
  # TF固有ステム
  tf_stem:
    kernel_size: 3                # 1D depth-wise CNN
    d_model: 128                  # 本番用大容量（test: 64）
    
  # クロススケールミキサー  
  encoder:
    n_layers: 8                   # 本番用深層（test: 4）
    d_model: 128                  # 本番用大容量（test: 64）
    d_state: 16                   # Mamba状態次元（test: 8）
    d_conv: 4                     # 畳み込み次元
    expand: 2                     # FFN拡張率
    cross_attn_every: 2           # 2層ごとにクロススケール注意
    flash_attn: true              # FlashAttention-2使用
    
  # Bottleneck
  bottleneck:
    latent_len: 32                # seq_len/4 = 128/4 = 32（動的計算）
    stride: 4                     # ストライド畳み込み
    
  # デコーダー
  decoder:
    n_layers: 4                   # 本番用深層（test: 2）
    kernel_size: 3                # 転置畳み込み
    
  # 位置エンコーディング
  positional:
    intra_tf: "rotary"            # TF内: 学習済みRotary
    inter_tf: "learned"           # TF間: 相対時間フレームID

# 損失設定
loss:
  weights:
    recon_tf: 0.6                 # Huber損失（TFごとのOHLC）
    spec_tf: 0.2                  # マルチ解像度STFT損失
    cross: 0.15                   # クロスTF整合性損失
    amp_phase: 0.05               # 振幅・位相相関損失
    
  huber_delta: 1.0                # Huber損失のデルタ
  stft_scales: [256, 512, 1024]   # 本番用フル解像度（test: [128, 256]）
  
# 訓練設定（本番用）
training:
  batch_size: 32                  # 大モデル用適正サイズ（test: 64）
  epochs: 40                      # 本番用長期訓練（test: 5）
  early_stop:
    patience: 8                   # 本番用忍耐（test: 3）
    min_delta: 0.0001             # 厳格な改善閾値
    
  # オプティマイザー
  optimizer:
    name: "AdamW"
    betas: [0.9, 0.999]           # 安定版（test: [0.9, 0.98]）
    weight_decay: 0.01
    
  # 学習率スケジューラー
  scheduler:
    name: "OneCycleLR"
    max_lr: 5.0e-4                # 本番用安定版（test: 1.0e-3）
    div_factor: 10                # 初期LR = max_lr/div_factor
    final_div_factor: 100         # 最終LR = max_lr/final_div_factor
    pct_start: 0.3                # 本番用ウォームアップ（test: 0.05）
    interval: "step"              # step単位で調整
    
  # 混合精度・勾配設定
  precision: "16-mixed"           # Tensor Core最適化
  gradient_clip: 1.0              # 勾配クリッピング
  accumulate_grad_batches: 4      # 勾配累積で見かけbatch_size=128

# データ拡張（本番では軽微に使用）
augmentation:
  ddim_noise:
    probability: 0.1              # 軽微なノイズ（test: 0.0）
  time_warp:
    probability: 0.05             # 軽微な時間歪み（test: 0.0）
  regime_mix:
    probability: 0.0              # 本番では無効化
    
# 検証・メトリクス
validation:
  val_split: 0.2                  # 20%を検証用
  metrics:
    - "correlation_per_tf"        # TFごとの相関
    - "consistency_ratio"         # 整合性比率
    - "spectral_delta"            # スペクトラムΔ
    - "amp_phase_corr"            # 振幅位相相関
    
# ログ・チェックポイント
logging:
  log_every_n_steps: 50           # 本番用頻繁ログ（test: 100）
  checkpoint_every_n_epochs: 2    # 本番用慎重保存（test: 1）
  save_top_k: 5                   # 本番用多重保存（test: 2）
  monitor: "val_correlation_mean"  # 監視メトリクス
  progress_bar_refresh_rate: 20   # Progress bar更新頻度
  
# 実行設定
runtime:
  seed: 42
  experiment_name: "production_v1"  # 実験名
  
# DataLoader最適化（本番用）
dataloader:
  num_workers: 12                 # 本番用多並列（test: 8）
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 6              # 本番用大容量プリフェッチ（test: 4）
  
# 本番用追加設定
production:
  target_correlation: 0.85        # 目標相関値
  max_training_time_hours: 24     # 最大訓練時間
  auto_lr_find: false             # 手動学習率設定
  resume_from_checkpoint: true    # チェックポイント自動復旧