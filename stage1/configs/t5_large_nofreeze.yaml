# T5è»¢ç§»å­¦ç¿’ - å‡çµãªã—ï¼ˆ10ã‚¨ãƒãƒƒã‚¯ç‰ˆï¼‰
# T5ã‚’æœ€åˆã‹ã‚‰å¾®èª¿æ•´ã€Early Stoppingä»˜ã

# ãƒ‡ãƒ¼ã‚¿è¨­å®š
data:
  seq_len: 128  # çµ±ä¸€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
  n_timeframes: 6                 # TFæ•° (M1, M5, M15, M30, H1, H4)
  n_features: 6                   # ç‰¹å¾´é‡æ•° [open, high, low, close, Î”close, %body]
  total_channels: 36              # 6ç‰¹å¾´é‡ Ã— 6TF = 36ãƒãƒ£ãƒ³ãƒãƒ«
  timeframes:
    - m1
    - m5  
    - m15
    - m30
    - h1
    - h4
  data_dir: "../data/derived"
  stats_file: "stats.json"
  # ğŸ”¥ Drop-in Sampling: ãƒ‡ãƒ¼ã‚¿ä¸å‡è¡¡å¯¾ç­–ï¼ˆçŸ­TFã®é‡è¤‡ç‡ã‚’ä¸‹ã’ã‚‹ï¼‰
  sampling_probs:
    m1: 1.00    # ğŸ”¥ M1ã¯å¿…ãšæ®‹ã™ï¼ˆCross-lossè¨ˆç®—ã«å¿…è¦ï¼‰
    m5: 0.40    # ä¸­é »åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    m15: 0.55   # ä¸­é »åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    m30: 0.70   # é«˜é »åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    h1: 0.85    # é«˜é »åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    h4: 1.00    # æœ€é«˜é »åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

# T5è»¢ç§»å­¦ç¿’è¨­å®š
transfer_learning:
  use_pretrained_lm: true
  lm_name_or_path: "t5-large"           # æ­£å¼IDï¼ˆç´„738M parametersï¼‰
  freeze_lm_epochs: 0                   # æœ€åˆã‹ã‚‰è§£å‡ + Layerwise LR Decay
  patch_len: 8                          # ğŸ”¥ M1æ”¹å–„: 128/8=16 patches (é«˜è§£åƒåº¦)
  lm_learning_rate_factor: 0.01         # T5å­¦ç¿’ç‡ã‚’10å€ã«èª¿æ•´

# ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆT5çµ±åˆï¼‰
model:
  # Model v2: éåŒæœŸãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š
  async_sampler: true               # ğŸ”¥ éåŒæœŸãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–ã§H4åˆ¶ç´„è§£é™¤
  cross_pairs:                      # coarseâ†’fine cross-attention pairs
    - ["h4", "m1"]
    - ["h1", "m1"] 
    - ["m30", "m1"]
    
  tf_stem:
    kernel_size: 3
    d_model: 1024                 # T5ã®d_modelã«åˆã‚ã›ã‚‹
    
  encoder:
    n_layers: 4                   # T5å¾Œã®è¿½åŠ å±¤æ•°
    d_model: 1024                 # T5ã®d_modelã«çµ±ä¸€
    d_state: 8
    d_conv: 4
    expand: 2
    cross_attn_every: 2
    flash_attn: false
    
  bottleneck:
    latent_len: 16                # seq_len/8 = 128/8 = 16
    stride: 8
    
  decoder:
    n_layers: 2
    kernel_size: 3
    
  positional:
    intra_tf: "rotary"
    inter_tf: "learned"

# è¨“ç·´è¨­å®šï¼ˆT5-Largeå®‰å®šåŒ–ï¼‰
training:
  batch_size: 32                  # ğŸ”¥ OOMå¯¾ç­–: ç·Šæ€¥å‰Šæ¸›ï¼ˆ768â†’32ï¼‰
  epochs: 7                       # 7ã‚¨ãƒãƒƒã‚¯è¨­å®š
  learning_rate: 1e-3
  weight_decay: 1e-4
  accumulate_grad_batches: 1      # ğŸ”¥ GPUåˆ©ç”¨ç‡æœ€é©åŒ–ï¼š1ã«å›ºå®š
  gradient_clip: 0.012            # 5å€ãƒ‡ãƒ¼ã‚¿å¯¾å¿œã§ç·©å’Œï¼ˆ0.008â†’0.012ï¼‰
  warmup_epochs: 1                # 5å€ãƒ‡ãƒ¼ã‚¿ç”¨ã«çŸ­ç¸®ï¼ˆå…¨ä½“ã®ç´„5%ï¼‰
  precision: "bf16-mixed"         # ğŸ”¥ H100æœ€é©åŒ–ï¼šBF16 Mixed Precisionã§é«˜é€ŸåŒ–
  early_stop:
    patience: 3                   # 3ã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—ã§æ—©æœŸçµ‚äº†
    min_delta: 0.001
    
  # çµ±ä¸€ã•ã‚ŒãŸã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š
  optimizer:
    name: "AdamW"
    lr: 1.5e-3                        # ãƒ˜ãƒƒãƒ‰ & Adapter ç”¨ã®åŸºæº– LRï¼ˆLR Finder v4æ¨å¥¨å€¤ - ãƒãƒƒãƒã‚µã‚¤ã‚º1024ç”¨ï¼‰
    betas: [0.9, 0.98]
    weight_decay: 0.01
    
  # Layerwise LR Decayè¨­å®š
  layerwise_lr_decay: 0.90             # ä¸‹ä½å±¤ã»ã© LR ã‚’ 0.90 å€ãšã¤æ¸›è¡°ï¼ˆç·©å’Œï¼‰
  t5_lr_top: 3.7e-4                    # T5 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€æœ€ä¸Šå±¤ç”¨ LRï¼ˆLR Finder v4æ¨å¥¨å€¤ - ãƒãƒƒãƒã‚µã‚¤ã‚º1024ç”¨ï¼‰
    
  # çµ±ä¸€ã•ã‚ŒãŸLRã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®š
  scheduler:
    name: "linear_with_warmup"  # Linear Warmup + Cosine Decay
    max_lr: 1.5e-3              # æœ€å¤§å­¦ç¿’ç‡ï¼ˆLR Finder v4æ¨å¥¨å€¤ - ãƒãƒƒãƒã‚µã‚¤ã‚º1024ç”¨ï¼‰
    div_factor: 10.0            # OneCycleLRç”¨ï¼ˆäº’æ›æ€§ä¿æŒï¼‰
    final_div_factor: 50
    pct_start: 0.10             
    interval: "step"            # ã‚¹ãƒ†ãƒƒãƒ—å˜ä½ã§æ›´æ–°

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆç„¡åŠ¹åŒ–ï¼‰
augmentation:
  ddim_noise:
    probability: 0.0
  time_warp:
    probability: 0.0
  regime_mix:
    probability: 0.0

# æ¤œè¨¼ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹
validation:
  val_split: 0.2
  val_gap_days: 60.0             # è¨“ç·´ã¨æ¤œè¨¼ã®é–“ã®æ™‚é–“çš„ã‚®ãƒ£ãƒƒãƒ—ï¼ˆæ—¥æ•°ï¼‰- 60æ—¥é–“ã§å®Œå…¨åˆ†é›¢
  metrics:
    - "correlation_per_tf"
    - "consistency_ratio"
    - "spectral_delta"

# è©•ä¾¡è¨­å®š (M1æ”¹å–„ + val_corr=0å•é¡Œä¿®æ­£)
evaluation:
  eval_mask_ratio: 0.15              # è©•ä¾¡æ™‚ã‚‚15%ãƒã‚¹ã‚¯ã‚’é©ç”¨ï¼ˆå­¦ç¿’æ™‚ã¨åŒæ¡ä»¶ï¼‰
  # ğŸ”¥ M1ã¯é«˜ãƒã‚¹ã‚¯ç‡ã§è©•ä¾¡ï¼ˆé«˜å‘¨æ³¢ãƒã‚¤ã‚ºè»½æ¸›ï¼‰
  tf_specific_mask_ratios:
    m1: 0.25                         # M1ã¯25%ãƒã‚¹ã‚¯ï¼ˆä»–ã‚ˆã‚Šå³ã—ãï¼‰
    m5: 0.15
    m15: 0.15  
    m30: 0.15
    h1: 0.15
    h4: 0.15

# ãƒ­ã‚°ãƒ»ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆ10ã‚¨ãƒãƒƒã‚¯æœ€é©åŒ–ï¼‰
logging:
  log_every_n_steps: 200          # ğŸ”¥ stdoutå‰Šæ¸›: 200stepæ¯ã®ã¿ãƒ­ã‚°
  checkpoint_every_n_epochs: 1    # æ¯ã‚¨ãƒãƒƒã‚¯è©•ä¾¡
  save_top_k: 2                   # ãƒ™ã‚¹ãƒˆ2ã®ã¿ä¿å­˜ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯ç¯€ç´„ï¼‰
  monitor: "val_correlation_mean"
  progress_bar_refresh_rate: 5    # ğŸ”¥ é€²æ—ç¢ºèª: 5stepæ¯ã«æ›´æ–°

# å®Ÿè¡Œè¨­å®š
runtime:
  seed: 42
  experiment_name: "t5_large_nofreeze"
  
# DataLoaderæœ€é©åŒ–ï¼ˆH100ã‚¯ãƒ©ã‚¦ãƒ‰GPUç”¨ï¼‰- é«˜æ€§èƒ½è¨­å®š
dataloader:
  num_workers: 32                 # ğŸ”¥ H100ç”¨: ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã®1/2ï¼ˆPython GIL + I/Oä¸¦åˆ—åŠ¹ç‡æœ€é©åŒ–ï¼‰
  pin_memory: true                # ğŸ”¥ H100ç”¨: HBMâ†’GPUè»¢é€ãƒœãƒˆãƒ«ãƒãƒƒã‚¯è§£æ¶ˆï¼ˆPCIeå¾…ã¡çŸ­ç¸®ï¼‰
  persistent_workers: true        # ğŸ”¥ H100ç”¨: æ¯ã‚¨ãƒãƒƒã‚¯fork/exitç„¡ã—ã§10-15%é«˜é€ŸåŒ–
  prefetch_factor: 4              # ğŸ”¥ H100ç”¨: å„ãƒ¯ãƒ¼ã‚«ãƒ¼4ãƒãƒƒãƒå…ˆèª­ã¿ï¼ˆGPUã‚’ç©ºã‹ã•ãªã„ï¼‰
  # ãƒ¡ãƒ¢ãƒªå¢—åŠ äºˆæƒ³: +4-5GBï¼ˆnum_workers:+1GB, pin_memory:+2GB, prefetch:+1-2GBï¼‰

# ãƒã‚¹ã‚­ãƒ³ã‚°è¨­å®šï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’ä¸€æ™‚ç„¡åŠ¹åŒ–ï¼‰
masking:
  mask_ratio: 0.15
  mask_span_min: 3
  mask_span_max: 10
  sync_across_tf: false
  mask_token_lr_scale: 1.0
  use_vectorized: true            # ğŸ”¥ ãƒ™ã‚¯ãƒˆãƒ«åŒ–æœ‰åŠ¹ï¼ˆ10å€é«˜é€Ÿï¼‰

# æ­£è¦åŒ–è¨­å®š
normalization:
  method: "zscore"
  per_tf: true

# ãƒ­ã‚¹è¨­å®šï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼‰
loss:
  weights:
    recon_tf: 0.6
    spec_tf: 0.0        # ğŸ”¥ ä¸€æ™‚ç„¡åŠ¹åŒ–ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–ï¼‰
    cross: 0.02         # ğŸ”¥ 33%å¢—åŠ ï¼ˆã‚¯ãƒ­ã‚¹æ•´åˆæ€§é‡è¦–ï¼‰
    amp_phase: 0.0      # ğŸ”¥ ä¸€æ™‚ç„¡åŠ¹åŒ–ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–ï¼‰
  huber_delta: 1.0
  stft_scales: [64, 128]  # ğŸ”¥ 256â†’128ã«å‰Šæ¸›ï¼ˆè¨ˆç®—é‡åŠæ¸›ï¼‰

# é–‹ç™ºç”¨è¨­å®šï¼ˆä¸­é–“è¦æ¨¡ãƒ†ã‚¹ãƒˆï¼‰
development:
  limit_train_batches: 3000       # ğŸ”¥ ä¸­é–“ãƒ†ã‚¹ãƒˆ: 3000ãƒãƒƒãƒ
  limit_val_batches: 600          # ğŸ”¥ ä¸­é–“ãƒ†ã‚¹ãƒˆ: 600ãƒãƒƒãƒï¼ˆæ¯”ä¾‹ï¼‰

# LR Finderè¨­å®š
lr_finder:
  enabled: false                  # LR Finderå®Œäº† - é€šå¸¸è¨“ç·´ãƒ¢ãƒ¼ãƒ‰
  min_lr: 1e-8                   # é–‹å§‹å­¦ç¿’ç‡
  max_lr: 1.0                    # çµ‚äº†å­¦ç¿’ç‡
  num_training: 100              # å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—æ•°
  mode: "exponential"            # å­¦ç¿’ç‡å¢—åŠ æ–¹æ³•
  save_path: "lr_finder_results" # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª