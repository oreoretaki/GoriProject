# T5è»¢ç§»å­¦ç¿’ - å‡çµãªã—ï¼ˆ10ã‚¨ãƒãƒƒã‚¯ç‰ˆï¼‰
# T5ã‚’æœ€åˆã‹ã‚‰å¾®èª¿æ•´ã€Early Stoppingä»˜ã

# å…±é€šè¨­å®šã‚’ç¶™æ‰¿
extends: shared_base.yaml

# T5è»¢ç§»å­¦ç¿’è¨­å®š
transfer_learning:
  use_pretrained_lm: true
  lm_name_or_path: "t5-large"           # æ­£å¼IDï¼ˆç´„738M parametersï¼‰
  freeze_lm_epochs: 0                   # æœ€åˆã‹ã‚‰è§£å‡ + Layerwise LR Decay
  patch_len: 16                         # 128/16=8 patches (6*16=96æ¬¡å…ƒ)
  lm_learning_rate_factor: 0.01         # T5å­¦ç¿’ç‡ã‚’10å€ã«èª¿æ•´

# ãƒ‡ãƒ¼ã‚¿è¨­å®šã¯ shared_base.yaml ã‹ã‚‰ç¶™æ‰¿

# ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆT5çµ±åˆï¼‰
model:
  # Model v2: éåŒæœŸãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š
  async_sampler: true               # ğŸ”¥ éåŒæœŸãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–ã§H4åˆ¶ç´„è§£é™¤
  cross_pairs:                      # coarseâ†’fine cross-attention pairs
    - ["h4", "m1"]
    - ["h1", "m1"] 
    - ["m30", "m1"]
    
  tf_stem:
    kernel_size: 3
    d_model: 1024                 # T5ã®d_modelã«åˆã‚ã›ã‚‹
    
  encoder:
    n_layers: 4                   # T5å¾Œã®è¿½åŠ å±¤æ•°
    d_model: 1024                 # T5ã®d_modelã«çµ±ä¸€
    d_state: 8
    d_conv: 4
    expand: 2
    cross_attn_every: 2
    flash_attn: true
    
  bottleneck:
    latent_len: 16                # seq_len/8 = 128/8 = 16
    stride: 8
    
  decoder:
    n_layers: 2
    kernel_size: 3
    
  positional:
    intra_tf: "rotary"
    inter_tf: "learned"

# è¨“ç·´è¨­å®šï¼ˆT5-Largeå®‰å®šåŒ–ï¼‰
training:
  batch_size: 512                 # H100æœ€é©åŒ–: 1024â†’512ï¼ˆOOMå¯¾ç­–ï¼‰
  epochs: 7                       # 7ã‚¨ãƒãƒƒã‚¯è¨­å®š
  accumulate_grad_batches: 1      # å®ŸåŠ¹ãƒãƒƒãƒã‚µã‚¤ã‚º1024
  warmup_epochs: 1              # 5å€ãƒ‡ãƒ¼ã‚¿ç”¨ã«çŸ­ç¸®ï¼ˆå…¨ä½“ã®ç´„5%ï¼‰
  early_stop:
    patience: 3                   # 3ã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—ã§æ—©æœŸçµ‚äº†
    min_delta: 0.001
    
  precision: "bf16"           # H100æœ€é©åŒ–ï¼šBF16ã§Tensor Coreæ´»ç”¨

# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆç„¡åŠ¹åŒ–ï¼‰
augmentation:
  ddim_noise:
    probability: 0.0
  time_warp:
    probability: 0.0
  regime_mix:
    probability: 0.0

# æ¤œè¨¼ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹
validation:
  val_split: 0.2
  metrics:
    - "correlation_per_tf"
    - "consistency_ratio"
    - "spectral_delta"

# è©•ä¾¡è¨­å®š (val_corr=0å•é¡Œä¿®æ­£)
evaluation:
  eval_mask_ratio: 0.15              # è©•ä¾¡æ™‚ã‚‚15%ãƒã‚¹ã‚¯ã‚’é©ç”¨ï¼ˆå­¦ç¿’æ™‚ã¨åŒæ¡ä»¶ï¼‰

# ãƒ­ã‚°ãƒ»ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆ10ã‚¨ãƒãƒƒã‚¯æœ€é©åŒ–ï¼‰
logging:
  log_every_n_steps: 10
  checkpoint_every_n_epochs: 1    # æ¯ã‚¨ãƒãƒƒã‚¯è©•ä¾¡
  save_top_k: 2                   # ãƒ™ã‚¹ãƒˆ2ã®ã¿ä¿å­˜ï¼ˆãƒ‡ã‚£ã‚¹ã‚¯ç¯€ç´„ï¼‰
  monitor: "val_correlation_mean"
  progress_bar_refresh_rate: 50

# å®Ÿè¡Œè¨­å®š
runtime:
  seed: 42
  experiment_name: "t5_large_nofreeze"
  
# DataLoaderæœ€é©åŒ–ï¼ˆT5ç”¨ï¼‰- shared_baseã‹ã‚‰ç¶™æ‰¿ã•ã‚Œã‚‹ãŒã€T5ç”¨ã«èª¿æ•´
dataloader:
  num_workers: 12                 # 18â†’12ã«å‰Šæ¸›ï¼ˆãƒ—ãƒ­ã‚»ã‚¹åˆ¶å¾¡å•é¡Œå›é¿ï¼‰
  pin_memory: true                # GPUè»¢é€é«˜é€ŸåŒ–
  persistent_workers: true        # ãƒ—ãƒ­ã‚»ã‚¹ç«‹ã¡ä¸Šã’ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å‰Šæ¸›
  prefetch_factor: 6              # å…ˆèª­ã¿å¼·åŒ–ï¼ˆ2â†’6ï¼‰

# é–‹ç™ºç”¨è¨­å®šï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ï¼‰
development:
  # limit_train_batches: 2383      # ğŸ”¥ åˆ¶é™è§£é™¤ï¼šå…¨ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
  # limit_val_batches: 606         # ğŸ”¥ åˆ¶é™è§£é™¤ï¼šå…¨ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
  # ğŸ”¥ shared_base.yamlã®åˆ¶é™ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
  limit_train_batches: null         # å®Œå…¨ã«åˆ¶é™è§£é™¤
  limit_val_batches: null           # å®Œå…¨ã«åˆ¶é™è§£é™¤