# LR Finder実行用設定
# T5-Large転移学習でLR Finderを実行

# 共通設定を継承
extends: shared_base.yaml

# LR Finder設定（バッチサイズ256用）
lr_finder:
  enabled: true                   # バッチサイズ256用のLR Finder有効化
  min_lr: 1e-7                   # 開始学習率を上げる
  max_lr: 1e-2                   # 終了学習率を下げる
  num_training: 200              # ステップ数を増やして詳細に
  mode: "exponential"            # 学習率増加方法
  save_path: "lr_finder_results_v3" # バッチサイズ256用結果保存ディレクトリ

# T5転移学習設定
transfer_learning:
  use_pretrained_lm: true
  lm_name_or_path: "t5-large"           # 正式ID（約738M parameters）
  freeze_lm_epochs: 0                   # 最初から解凍 + Layerwise LR Decay
  patch_len: 32                         # 128/32=4 patches
  lm_learning_rate_factor: 0.01         # T5学習率を10倍に調整

# モデルアーキテクチャ（T5統合）
model:
  tf_stem:
    kernel_size: 3
    d_model: 64                   # T5出力をこの次元に投影
    
  encoder:
    n_layers: 4                   # T5後の追加層数
    d_model: 64                   # Stage-1の次元（T5から投影）
    d_state: 8
    d_conv: 4
    expand: 2
    cross_attn_every: 2
    flash_attn: true
    
  bottleneck:
    latent_len: 16                # seq_len/8 = 128/8 = 16
    stride: 8
    
  decoder:
    n_layers: 2
    kernel_size: 3
    
  positional:
    intra_tf: "rotary"
    inter_tf: "learned"

# 訓練設定（LR Finder用）
training:
  batch_size: 256                 # H100用バッチサイズ256
  epochs: 1                       # LR Finderは1エポックのみ
  accumulate_grad_batches: 1      # 実効バッチサイズ256
  warmup_epochs: 0.1              # 軽いwarmupを追加（10%）
  early_stop:
    patience: 3
    min_delta: 0.001
    
  precision: "32"                 # NaN対策：AMP無効化、FP32固定

# データ拡張（無効化）
augmentation:
  ddim_noise:
    probability: 0.0
  time_warp:
    probability: 0.0
  regime_mix:
    probability: 0.0

# 検証・メトリクス
validation:
  val_split: 0.2
  metrics:
    - "correlation_per_tf"
    - "consistency_ratio"
    - "spectral_delta"

# ログ・チェックポイント（LR Finder用最小限）
logging:
  log_every_n_steps: 50
  checkpoint_every_n_epochs: 1
  save_top_k: 1                   # 1つのみ保存
  monitor: "val_correlation_mean"
  progress_bar_refresh_rate: 10

# 実行設定
runtime:
  seed: 42
  experiment_name: "lr_finder_batch256"
  
# DataLoader最適化（LR Finder用）
dataloader:
  num_workers: 18                 # CPU並列化
  pin_memory: true                # GPU転送高速化
  persistent_workers: true        # ワーカー再利用

# LR Finder用最小データセット
development:
  limit_train_batches: 200        # LR Finder用にさらに削減
  limit_val_batches: 40           # 検証も削減