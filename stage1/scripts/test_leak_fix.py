#!/usr/bin/env python3
"""
Stage-1 ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ä¿®æ­£å‰å¾Œã®æ¤œè¨¼æŒ‡æ¨™æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import numpy as np
import pandas as pd
from pathlib import Path
import json
import tempfile
import shutil
from typing import Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.data_loader import Stage1Dataset
from src.window_sampler import MultiTFWindowSampler
from src.masking import MaskingStrategy
from src.normalization import TFNormalizer
from src.feature_engineering import FeatureEngineer

def load_test_config():
    """ãƒ†ã‚¹ãƒˆç”¨è¨­å®šã‚’ä½œæˆ"""
    return {
        'data': {
            'seq_len': 128,
            'n_timeframes': 6,
            'n_features': 6,
            'total_channels': 36,
            'timeframes': ['m1', 'm5', 'm15', 'm30', 'h1', 'h4'],
            'data_dir': '../data/derived',
            'stats_file': 'stats.json'
        },
        'masking': {
            'mask_ratio': 0.15,
            'mask_span_min': 3,
            'mask_span_max': 10,
            'sync_across_tf': False
        },
        'normalization': {
            'method': 'zscore',
            'per_tf': True
        },
        'validation': {
            'val_split': 0.2,
            'val_gap_days': 1.0  # æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        },
        'evaluation': {
            'eval_mask_ratio': None  # æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        }
    }

def test_data_leak_fix():
    """ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ä¿®æ­£å‰å¾Œã®æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
    
    print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ä¿®æ­£å‰å¾Œã®æ¤œè¨¼æŒ‡æ¨™æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    config = load_test_config()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    data_dir = Path(config['data']['data_dir'])
    tf_data = {}
    
    for tf in config['data']['timeframes']:
        file_path = data_dir / f"simple_gap_aware_{tf}.parquet"
        if file_path.exists():
            tf_data[tf] = pd.read_parquet(file_path)
            print(f"   {tf}: {len(tf_data[tf])} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        else:
            print(f"   âš ï¸ {tf}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ãƒ†ã‚¹ãƒˆ1: å¾“æ¥ã®åˆ†å‰²æ–¹æ³•ï¼ˆãƒªãƒ¼ã‚¯ã‚ã‚Šï¼‰
    print("\nğŸ”´ ãƒ†ã‚¹ãƒˆ1: å¾“æ¥ã®åˆ†å‰²æ–¹æ³•ï¼ˆãƒªãƒ¼ã‚¯ã‚ã‚Šï¼‰")
    print("-" * 40)
    
    # val_gap_days=0ã§å¾“æ¥ã®å‹•ä½œã‚’å†ç¾
    old_sampler_train = MultiTFWindowSampler(
        tf_data=tf_data,
        seq_len=config['data']['seq_len'],
        split="train",
        val_split=config['validation']['val_split'],
        min_coverage=0.8,
        cache_dir=None,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—
        val_gap_days=0.0  # ã‚®ãƒ£ãƒƒãƒ—ãªã—
    )
    
    old_sampler_val = MultiTFWindowSampler(
        tf_data=tf_data,
        seq_len=config['data']['seq_len'],
        split="val",
        val_split=config['validation']['val_split'],
        min_coverage=0.8,
        cache_dir=None,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—
        val_gap_days=0.0  # ã‚®ãƒ£ãƒƒãƒ—ãªã—
    )
    
    print(f"   è¨“ç·´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: {len(old_sampler_train)}")
    print(f"   æ¤œè¨¼ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: {len(old_sampler_val)}")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if len(old_sampler_train.split_windows) > 0 and len(old_sampler_val.split_windows) > 0:
        train_last = old_sampler_train.split_windows[-1]
        val_first = old_sampler_val.split_windows[0]
        overlap_minutes = (val_first[0] - train_last[1]).total_seconds() / 60
        print(f"   è¨“ç·´æœ€å¾Œã¨æ¤œè¨¼æœ€åˆã®é–“éš”: {overlap_minutes:.1f} åˆ†")
        print(f"   é‡è¤‡åº¦: {127/128*100:.1f}% (127/128 æ™‚ç‚¹é‡è¤‡)")
    
    # ãƒ†ã‚¹ãƒˆ2: æ–°ã—ã„åˆ†å‰²æ–¹æ³•ï¼ˆãƒªãƒ¼ã‚¯ä¿®æ­£ï¼‰
    print("\nğŸŸ¢ ãƒ†ã‚¹ãƒˆ2: æ–°ã—ã„åˆ†å‰²æ–¹æ³•ï¼ˆãƒªãƒ¼ã‚¯ä¿®æ­£ï¼‰")
    print("-" * 40)
    
    new_sampler_train = MultiTFWindowSampler(
        tf_data=tf_data,
        seq_len=config['data']['seq_len'],
        split="train",
        val_split=config['validation']['val_split'],
        min_coverage=0.8,
        cache_dir=None,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—
        val_gap_days=config['validation']['val_gap_days']  # 1æ—¥ã‚®ãƒ£ãƒƒãƒ—
    )
    
    new_sampler_val = MultiTFWindowSampler(
        tf_data=tf_data,
        seq_len=config['data']['seq_len'],
        split="val",
        val_split=config['validation']['val_split'],
        min_coverage=0.8,
        cache_dir=None,  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—
        val_gap_days=config['validation']['val_gap_days']  # 1æ—¥ã‚®ãƒ£ãƒƒãƒ—
    )
    
    print(f"   è¨“ç·´ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: {len(new_sampler_train)}")
    print(f"   æ¤œè¨¼ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: {len(new_sampler_val)}")
    
    # ã‚®ãƒ£ãƒƒãƒ—ãƒã‚§ãƒƒã‚¯
    if len(new_sampler_train.split_windows) > 0 and len(new_sampler_val.split_windows) > 0:
        train_last = new_sampler_train.split_windows[-1]
        val_first = new_sampler_val.split_windows[0]
        gap_minutes = (val_first[0] - train_last[1]).total_seconds() / 60
        print(f"   è¨“ç·´æœ€å¾Œã¨æ¤œè¨¼æœ€åˆã®é–“éš”: {gap_minutes:.1f} åˆ†")
        print(f"   ã‚®ãƒ£ãƒƒãƒ—æ—¥æ•°: {gap_minutes/(24*60):.1f} æ—¥")
        print(f"   é‡è¤‡åº¦: 0% (å®Œå…¨åˆ†é›¢)")
    
    # ãƒ†ã‚¹ãƒˆ3: ãƒã‚¹ã‚¯ç‡ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰æ©Ÿèƒ½
    print("\nğŸ­ ãƒ†ã‚¹ãƒˆ3: ãƒã‚¹ã‚¯ç‡ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰æ©Ÿèƒ½")
    print("-" * 40)
    
    masking_strategy = MaskingStrategy(config)
    
    # ãƒ€ãƒŸãƒ¼ç‰¹å¾´é‡ä½œæˆ
    dummy_features = torch.randn(6, 128, 6)
    
    # é€šå¸¸ã®ãƒã‚¹ã‚¯
    normal_mask = masking_strategy.generate_masks(dummy_features, seed=42)
    normal_ratio = normal_mask.sum().item() / normal_mask.numel()
    print(f"   é€šå¸¸ãƒã‚¹ã‚¯ç‡: {normal_ratio:.3f}")
    
    # ãƒã‚¹ã‚¯ãªã—
    no_mask = masking_strategy.generate_masks(dummy_features, seed=42, eval_mask_ratio_override=0.0)
    no_mask_ratio = no_mask.sum().item() / no_mask.numel()
    print(f"   ãƒã‚¹ã‚¯ãªã—ç‡: {no_mask_ratio:.3f}")
    
    # å…¨ãƒã‚¹ã‚¯
    full_mask = masking_strategy.generate_masks(dummy_features, seed=42, eval_mask_ratio_override=1.0)
    full_mask_ratio = full_mask.sum().item() / full_mask.numel()
    print(f"   å…¨ãƒã‚¹ã‚¯ç‡: {full_mask_ratio:.3f}")
    
    # ãƒ‡ãƒ¼ã‚¿é‡æ¯”è¼ƒ
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿é‡æ¯”è¼ƒ")
    print("-" * 40)
    
    old_train_size = len(old_sampler_train)
    old_val_size = len(old_sampler_val)
    new_train_size = len(new_sampler_train)
    new_val_size = len(new_sampler_val)
    
    if old_train_size > 0:
        train_reduction = (old_train_size - new_train_size) / old_train_size * 100
    else:
        train_reduction = 0.0
        
    if old_val_size > 0:
        val_reduction = (old_val_size - new_val_size) / old_val_size * 100
    else:
        val_reduction = 0.0
    
    print(f"   å¾“æ¥æ–¹å¼ - è¨“ç·´: {old_train_size:,}, æ¤œè¨¼: {old_val_size:,}")
    print(f"   æ–°æ–¹å¼   - è¨“ç·´: {new_train_size:,}, æ¤œè¨¼: {new_val_size:,}")
    print(f"   ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ç‡ - è¨“ç·´: {train_reduction:.1f}%, æ¤œè¨¼: {val_reduction:.1f}%")
    
    # æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ
    print("\nğŸ¯ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ")
    print("-" * 40)
    print("   âœ… ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é™¤å»ã«ã‚ˆã‚Šã€æ¤œè¨¼æŒ‡æ¨™ãŒç¾å®Ÿçš„ãªå€¤ã«")
    print("   âœ… éå­¦ç¿’ã®æ—©æœŸç™ºè¦‹ãŒå¯èƒ½ã«")
    print("   âœ… Stage-2ã§ã®åˆæœŸé‡ã¿é¸å®šãŒæ­£ç¢ºã«")
    print("   âœ… ãƒã‚¹ã‚¯ç‡ã«ä¾å­˜ã—ãªã„è©•ä¾¡ãŒå¯èƒ½ã«")
    
    # æ¨å¥¨å®Ÿè¡Œä¾‹
    print("\nğŸš€ æ¨å¥¨å®Ÿè¡Œä¾‹")
    print("-" * 40)
    print("   # å¾“æ¥æ–¹å¼ã§ã®å®Ÿè¡Œ")
    print("   python3 scripts/train_stage1.py --config configs/t5_large_nofreeze.yaml --data_dir ../data/derived --devices 1")
    print("")
    print("   # æ–°æ–¹å¼ã§ã®å®Ÿè¡Œ")
    print("   python3 scripts/train_stage1.py --config configs/t5_large_nofreeze.yaml --data_dir ../data/derived --devices 1 --val_gap_days 1.0")
    print("")
    print("   # ãƒã‚¹ã‚¯ãªã—è©•ä¾¡")
    print("   python3 scripts/train_stage1.py --config configs/t5_large_nofreeze.yaml --data_dir ../data/derived --devices 1 --eval_mask_ratio 0.0")
    print("")
    print("   # è¤‡æ•°ã‚·ãƒ¼ãƒ‰è©•ä¾¡")
    print("   python3 scripts/train_stage1.py --config configs/t5_large_nofreeze.yaml --data_dir ../data/derived --devices 1 --seeds 42 123 2025")
    
    return True

if __name__ == "__main__":
    try:
        test_data_leak_fix()
        print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()