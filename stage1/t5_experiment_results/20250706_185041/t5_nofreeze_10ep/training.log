[rank: 0] Seed set to 42
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loading `train_dataloader` to estimate number of stepping batches.
ğŸš€ Stage 1 è¨“ç·´é–‹å§‹
   è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: configs/t5_nofreeze_10ep.yaml
   ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../data/derived
   ãƒ‡ãƒã‚¤ã‚¹æ•°: 1
ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆä¸­...
ğŸ”„ Stage 1 DatasetåˆæœŸåŒ– (train)
   ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../data/derived
   æ™‚é–“è¶³: ['m1', 'm5', 'm15', 'm30', 'h1', 'h4']
   ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: 128
   M1: 3,104,383ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:24:00+00:00
   M5: 630,474ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:20:00+00:00
   M15: 210,477ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:15:00+00:00
   M30: 105,252ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:00:00+00:00
   H1: 52,632ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:00:00+00:00
   H4: 13,601ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 20:00:00+00:00
ğŸ”§ FeatureEngineeråˆæœŸåŒ–
   ç‰¹å¾´é‡æ•°: 6
   ç‰¹å¾´é‡: ['open', 'high', 'low', 'close', 'delta_close', 'body_ratio']
ğŸ“ TFNormalizeråˆæœŸåŒ–
   çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«: ../data/derived/stats.json
   ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹: True
ğŸ“‚ æ­£è¦åŒ–çµ±è¨ˆãƒ­ãƒ¼ãƒ‰å®Œäº†: 2å€‹ã®TF
ğŸ”„ MultiTFWindowSampleråˆæœŸåŒ– (train)
   ğŸ“‚ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦èª­ã¿è¾¼ã¿: windows_d4ec0e80.npy
   âš¡ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å‡¦ç†æ™‚é–“: 49.33ç§’
   ç·ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: 3104256
   trainã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: 2483405
ğŸ­ MaskingStrategyåˆæœŸåŒ–
   ãƒã‚¹ã‚¯ç‡: 0.15
   ã‚¹ãƒ‘ãƒ³ç¯„å›²: 3-10
   TFé–“åŒæœŸ: True
ğŸ”„ Stage 1 DatasetåˆæœŸåŒ– (val)
   ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ../data/derived
   æ™‚é–“è¶³: ['m1', 'm5', 'm15', 'm30', 'h1', 'h4']
   ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·: 128
   M1: 3,104,383ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:24:00+00:00
   M5: 630,474ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:20:00+00:00
   M15: 210,477ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:15:00+00:00
   M30: 105,252ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:00:00+00:00
   H1: 52,632ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 23:00:00+00:00
   H4: 13,601ãƒ¬ã‚³ãƒ¼ãƒ‰, æœŸé–“: 2017-01-03 08:00:00+00:00 - 2025-06-17 20:00:00+00:00
ğŸ”§ FeatureEngineeråˆæœŸåŒ–
   ç‰¹å¾´é‡æ•°: 6
   ç‰¹å¾´é‡: ['open', 'high', 'low', 'close', 'delta_close', 'body_ratio']
ğŸ“ TFNormalizeråˆæœŸåŒ–
   çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«: ../data/derived/stats.json
   ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹: True
ğŸ“‚ æ­£è¦åŒ–çµ±è¨ˆãƒ­ãƒ¼ãƒ‰å®Œäº†: 2å€‹ã®TF
ğŸ”„ MultiTFWindowSampleråˆæœŸåŒ– (val)
   ğŸ“‚ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦èª­ã¿è¾¼ã¿: windows_d4ec0e80.npy
   âš¡ ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å‡¦ç†æ™‚é–“: 45.74ç§’
   ç·ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: 3104256
   valã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ•°: 620851
ğŸ­ MaskingStrategyåˆæœŸåŒ–
   ãƒã‚¹ã‚¯ç‡: 0.15
   ã‚¹ãƒ‘ãƒ³ç¯„å›²: 3-10
   TFé–“åŒæœŸ: True
ğŸ“Š DataLoaderä½œæˆå®Œäº†
   è¨“ç·´: 77606ãƒãƒƒãƒ (2483405ã‚µãƒ³ãƒ—ãƒ«)
   æ¤œè¨¼: 19401ãƒãƒƒãƒ (620851ã‚µãƒ³ãƒ—ãƒ«)
   æœ€é©åŒ–: num_workers=3, prefetch=4
ğŸ§  ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...
ğŸ¤— T5è»¢ç§»å­¦ç¿’ã‚’ä½¿ç”¨ã—ã¾ã™
ğŸ¤— T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: t5-small
ğŸ”’ T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å‡çµã—ã¾ã—ãŸ
âœ… T5TimeSeriesAdapteråˆæœŸåŒ–å®Œäº†
   T5 d_model: 512
   Stage-1 d_model: 64
   Patch length: 32
   åˆæœŸå‡çµã‚¨ãƒãƒƒã‚¯æ•°: 0
ğŸ¯ Stage1CombinedLossåˆæœŸåŒ–
   æå¤±é‡ã¿: {'recon_tf': 0.6, 'spec_tf': 0.2, 'cross': 0.15, 'amp_phase': 0.05}
âš¡ Stage1LightningModuleåˆæœŸåŒ–å®Œäº†
   ãƒ¢ãƒ‡ãƒ«æƒ…å ±: {'total_parameters': 36763560, 'trainable_parameters': 1432744, 'model_size_mb': 140.24185180664062, 'architecture': {'n_tf': 6, 'seq_len': 128, 'n_features': 6, 'd_model': 64, 'latent_len': 'dynamic(16)'}}
ğŸ¤— T5æ®µéšçš„è§£å‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿½åŠ  (freeze_epochs=0)
ğŸ¤— T5å·®åˆ†å­¦ç¿’ç‡ã‚’é©ç”¨: base_lr=1.00e-03, t5_lr=1.00e-05

  | Name      | Type               | Params | Mode 
---------------------------------------------------------
0 | model     | Stage1Model        | 36.8 M | train
1 | criterion | Stage1CombinedLoss | 0      | train
---------------------------------------------------------
1.4 M     Trainable params
35.3 M    Non-trainable params
36.8 M    Total params
147.054   Total estimated model params size (MB)
102       Modules in train mode
115       Modules in eval mode
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  0.22it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/100 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s] ğŸ”“ T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å‡çµã‚’è§£é™¤ã—ã¾ã—ãŸ
ğŸ”“ ã‚¨ãƒãƒƒã‚¯0: T5ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®å‡çµã‚’è§£é™¤
Traceback (most recent call last):
  File "/mnt/c/Users/taki/Desktop/my-projects/GoriProject/stage1/scripts/train_stage1.py", line 636, in <module>
    main()
  File "/mnt/c/Users/taki/Desktop/my-projects/GoriProject/stage1/scripts/train_stage1.py", line 615, in main
    trainer.fit(model, train_loader, val_loader)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 561, in fit
    call._call_and_handle_interrupt(
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 48, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 599, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1012, in _run
    results = self._run_stage()
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1056, in _run_stage
    self.fit_loop.run()
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 455, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 344, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/GoriProject/stage1/scripts/train_stage1.py", line 207, in optimizer_step
    return super().optimizer_step(epoch, batch_idx, optimizer, optimizer_closure)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1328, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/amp.py", line 79, in optimizer_step
    closure_result = closure()
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 328, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 215, in backward
    closure_loss = self.precision_plugin.post_backward(closure_loss, self.lightning_module)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py", line 81, in post_backward
    call._call_lightning_module_hook(trainer, "on_after_backward")
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 176, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/mnt/c/Users/taki/Desktop/my-projects/GoriProject/stage1/scripts/train_stage1.py", line 315, in on_after_backward
    self.trainer.logger.experiment.add_histogram(
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py", line 499, in add_histogram
    histogram(tag, values, bins, max_bins=max_bins), global_step, walltime
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/torch/utils/tensorboard/summary.py", line 485, in histogram
    hist = make_histogram(values.astype(float), bins, max_bins)
  File "/mnt/c/Users/taki/Desktop/my-projects/OANDI/ts_transformer_rl/GORI/venv/lib/python3.10/site-packages/torch/utils/tensorboard/summary.py", line 530, in make_histogram
    raise ValueError("The histogram is empty, please file a bug report.")
ValueError: The histogram is empty, please file a bug report.
Epoch 0:   0%|          | 0/100 [00:20<?, ?it/s]